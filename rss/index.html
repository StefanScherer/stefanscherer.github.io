<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[Stefan Scherer's Blog]]></title><description><![CDATA[Just my techie notes.]]></description><link>https://stefanscherer.github.io/</link><image><url>https://stefanscherer.github.io/favicon.png</url><title>Stefan Scherer&apos;s Blog</title><link>https://stefanscherer.github.io/</link></image><generator>Ghost 1.8</generator><lastBuildDate>Wed, 03 Oct 2018 14:41:15 GMT</lastBuildDate><atom:link href="https://stefanscherer.github.io/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[What's new for Docker on Windows Server 2019?]]></title><description><![CDATA[<div class="kg-card-markdown"><p>Last week at MS Ignite Microsoft has announced the new Windows Server 2019 which will be general available in October. This is a big new release with a lot of improvements using Docker with Windows Containers. Here is an overview of relevant changes.</p>
<p>Since the last two years after Windows</p></div>]]></description><link>https://stefanscherer.github.io/docker-on-windows-server-2019/</link><guid isPermaLink="false">5ba63112078c7c0001c0a3e8</guid><category><![CDATA[Docker]]></category><category><![CDATA[Windows Server 2019]]></category><dc:creator><![CDATA[Stefan Scherer]]></dc:creator><pubDate>Wed, 03 Oct 2018 14:00:00 GMT</pubDate><content:encoded><![CDATA[<div class="kg-card-markdown"><p>Last week at MS Ignite Microsoft has announced the new Windows Server 2019 which will be general available in October. This is a big new release with a lot of improvements using Docker with Windows Containers. Here is an overview of relevant changes.</p>
<p>Since the last two years after Windows Server 2016 first introduced Windows Container support a lot of things have improved. We have seen some of that changes in the semi-annual releases of 1709 and 1803, and now the long-term supported release has all the latest and greatest updates available.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/10/Bildschirmfoto-2018-10-03-um-11.18.17.png" alt="Windows Server 2019 with Docker installed"></p>
<h2 id="inplaceupdatefrom2012r22016">In-Place update from 2012 R2 / 2016</h2>
<p>First of all if you have older Windows Servers running it is possible to install an in-place update to this new release. So it is possible to run Windows Containers after updating your server, adding the <strong>Containers feature</strong> and <strong>installing Docker</strong> on your server. I normally create fresh machines with the new operating system, but this update really looks interesting to get access to these new technology.</p>
<h2 id="smallerbasedockerimages">Smaller base Docker images</h2>
<p>The containers team at Microsoft has improved the size of the Windows base images. The container images have been shrunk down to 1/3 to 1/4 of the equivalent 2016 images. The sizes in the diagram below are the sizes after downloading and expanding the Docker images and running the <code>docker images</code> command.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/10/Bildschirmfoto-2018-10-03-um-15.46.33.png" alt="Comparison of Docker image sizes for 2016 and 2019"></p>
<p>With the very small <code>mcr.microsoft.com/nanoserver:sac2019</code> image you will see applications at about 100 MByte (compressed) on Docker Hub.</p>
<h2 id="anewwindowsbaseimage">A new windows base image</h2>
<p>In addition to the two known Windows base images for <strong>Windows Server Core</strong> and <strong>Nano Server</strong> there is now a third base image: <strong>Windows</strong></p>
<p><img src="https://stefanscherer.github.io/content/images/2018/10/Bildschirmfoto-2018-10-03-um-16.03.46.png" alt="Three Windows base OS images"></p>
<p>This image gives you an even broader support for your Windows applications than just the core image. One use-case is for automation workloads like automated UI tests. But notice you still cannot RDP into such Windows containers.</p>
<h2 id="transitiontomcrmicrosoftcom">Transition to <code>mcr.microsoft.com</code></h2>
<p>Microsoft has started to move its Docker images from the Docker Hub into a own container registry. What you have to know is that the name for the base images will slightly change. You only have to remember to change the <code>microsoft/</code> to <code>mcr.microsoft.com/</code>. The following example shows the old and the new image name.</p>
<pre><code>FROM microsoft/windowsservercore
</code></pre>
<p>to</p>
<pre><code>FROM mcr.microsoft.com/windowsservercore
</code></pre>
<p>The tags on Docker Hub are still there and you still will be able to pull the images with the old image name for a while.</p>
<p>The Windows base images has always been hosted on Microsoft CDN as &quot;foreign layers&quot;, so really only the tag names changes.</p>
<p>A good question is where can you find the new images. The <code>mcr.microsoft.com</code> registry does not have an UI.</p>
<p>At the time of writing this blog post the new Docker images are not available. The latest information that can be found is on Docker Hub for the Insider images:</p>
<p><a href="https://hub.docker.com/r/microsoft/nanoserver-insider/">https://hub.docker.com/r/microsoft/nanoserver-insider/</a><br>
<a href="https://hub.docker.com/r/microsoft/windowsservercore-insider/">https://hub.docker.com/r/microsoft/windowsservercore-insider/</a><br>
<a href="https://hub.docker.com/r/microsoft/windows-insider/">https://hub.docker.com/r/microsoft/windows-insider/</a></p>
<p>My assumption is to see the new tags described on Docker Hub here:</p>
<p><a href="https://hub.docker.com/r/microsoft/nanoserver/">https://hub.docker.com/r/microsoft/nanoserver/</a><br>
<a href="https://hub.docker.com/r/microsoft/windowsservercore/">https://hub.docker.com/r/microsoft/windowsservercore/</a><br>
<a href="https://hub.docker.com/r/microsoft/windows/">https://hub.docker.com/r/microsoft/windows/</a>  (still 404)</p>
<p>I'll update the blog post once the new images have arrived.</p>
<h2 id="portsbindtolocalhost">Ports bind to localhost</h2>
<p>When you bind a container port to a host port your containerized application can be accessed with localhost from the host. This is what we are used with Linux containers since the beginning and now you no longer have to find out the container IP address to access your application.</p>
<pre><code>docker run -p 80:80 mcr.microsoft.com/iis
start http://localhost:80
</code></pre>
<h2 id="ingressnetworking">Ingress networking</h2>
<p>I have tried one of the latest Insider builds to create a <strong>Docker Swarm</strong> with multiple Windows machines. And I'm happy to see that you can create a Windows-only Docker Swarm with manager nodes and worker nodes.<br>
I was also able to access the published port of a web server running in Windows containers.</p>
<p>After scaling that service up to have it running multiple times spread over all swarm nodes I also could see the load-balancing is working in such a Windows-only cluster.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/10/Bildschirmfoto-2018-10-03-um-16.28.26.png" alt="Service running in Windows-only docker swarm"></p>
<h2 id="namedpipesinwindowscontainers">Named pipes in Windows containers</h2>
<p>Another nice improvement is that you can bind Windows named pipes from the host into Windows containers.</p>
<p>Some tools like Traefik, Portainer UI or another Docker client want to access the Docker API and we know we could bind the Unix socket into Linux containers. With Windows Server 2019 it is possible to do the same with the Docker named pipe.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/10/Bildschirmfoto-2018-10-03-um-16.25.39.png" alt="Portainer and local Docker named pipe"></p>
<h2 id="lcow">LCOW?</h2>
<p>I could not find any announcement at MS Ignite about Linux Containers on Windows.</p>
<p>So I tried the steps to manually install the LinuxKit kernel and updated to the latest Docker EE 18.03.1-ee-3 version.</p>
<p>In this combination LCOW really works</p>
<h2 id="getitnow">Get it now</h2>
<p>Go and get in touch with the new Windows Server 2019.</p>
<ul>
<li>Spin up a Windows Server 2019 from the Azure Marketplace.</li>
<li>Go to your MSDN subscription and download the ISO.</li>
<li>Go to the Evaluation Center <a href="https://www.microsoft.com/en-us/evalcenter/evaluate-windows-server-2019">https://www.microsoft.com/en-us/evalcenter/evaluate-windows-server-2019</a> and download the VHD or ISO.</li>
<li>Pick my Vagrant box from <a href="https://app.vagrantup.com/StefanScherer/boxes/windows_2019">Vagrant Cloud</a> suitable for VMware Workstation/Fusion, Hyper-V and VirtualBox.</li>
</ul>
<h2 id="tldr">TL/DR</h2>
<p>When you work with Windows Containers I recommand to switch over to the new Windows Server 2019 release. It is much simpler now to work with Windows containers. With the smaller images you can deploy your application even faster.</p>
<p>You still can run your old containers from 2016 in Hyper-V isolation mode, but I recommend to rebuild them with the new Windows base images to experience faster downloads and start times.</p>
</div>]]></content:encoded></item><item><title><![CDATA[How to use AppVeyor to build a multi-arch Docker image for Linux and Windows]]></title><description><![CDATA[<div class="kg-card-markdown"><p>After some months of private beta AppVeyor recently has announced general availability of their Linux build agents. In this blog post I want to show you what we can do with this new feature.</p>
<p>In <a href="https://stefanscherer.github.io/fork-appveyor-buildpipeline/">my previous blog post</a> I showed how you can fork the example repo and build</p></div>]]></description><link>https://stefanscherer.github.io/use-appveyor-to-build-multi-arch-docker-image/</link><guid isPermaLink="false">5b12c82dd71f9600016d99ed</guid><category><![CDATA[Docker]]></category><category><![CDATA[Docker Hub]]></category><category><![CDATA[AppVeyor]]></category><category><![CDATA[multi-arch]]></category><dc:creator><![CDATA[Stefan Scherer]]></dc:creator><pubDate>Sat, 02 Jun 2018 18:13:19 GMT</pubDate><content:encoded><![CDATA[<div class="kg-card-markdown"><p>After some months of private beta AppVeyor recently has announced general availability of their Linux build agents. In this blog post I want to show you what we can do with this new feature.</p>
<p>In <a href="https://stefanscherer.github.io/fork-appveyor-buildpipeline/">my previous blog post</a> I showed how you can fork the example repo and build it your own, adjust it and learn all the details of the application, the Dockerfiles and the build steps.</p>
<p>This blog post shows the details about a Linux and Windows builds and how you can combine that to a multi-arch Docker image.</p>
<h1 id="whatisappveyor">What is AppVeyor?</h1>
<p>But first we have to start with AppVeyor. The GitHub market place shows a lot of offerings for <a href="https://github.com/marketplace/category/continuous-integration">continuous integration</a>. This is what you normally want to have automatic tests for each Git commit or pull request you receive.</p>
<p>AppVeyor is my #1 place to go if I want Windows builds. I use it for several years now, you can do your .NET builds, native C/C++ builds and even Windows Containers with it. It is really easy to attach it to your GitHub repo with a YAML file.</p>
<h1 id="whoami">Whoami</h1>
<p>After the announcement for the new Linux build agents I looked into my sample <a href="https://github.com/StefanScherer/whoami">whoami repo</a> that builds a multi-arch Docker image that works both for Linux and Windows. I was curious to find out how the Linux builds work on AppVeyor. Because then I can just use one CI provider instead of two different.</p>
<p>The CI pipeline before that evening looked like this.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/pipeline-old.png" alt="pipeline-old"></p>
<p>I used <a href="https://travis-ci.org">Travis CI</a> for all the Linux builds. There was a build matrix to build Linux Docker images for three different CPU architectures: x64, arm and arm64.</p>
<p>For the Windows builds I already used <a href="https://www.appveyor.com">AppVeyor</a> as they provider Docker builds as well.</p>
<p>The difficult part was to synchronise all builds to run the final step to create a Docker manifest that combines all Docker images to just one manifest.</p>
<h1 id="twoyamls">Two YAMLs</h1>
<p>I opened the two YAML files that describe the CI pipeline for each service:</p>
<ul>
<li><code>appveyor.yml</code> for Windows on the left side</li>
<li><code>.travis.yml</code> for Linux on the right side</li>
</ul>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/migrate-travis-to-appveyor-01.png" alt="migrate-travis-to-appveyor-01"></p>
<p>The YAML have a similar structure. There are three steps</p>
<ul>
<li>build</li>
<li>test</li>
<li>deploy (if it's a tagged release build)</li>
</ul>
<p>And the Travis build has a build matrix for three variants.</p>
<p>I started to draft the updated <code>appveyor.yml</code> how it could look like when the Linux build gets migrated from the <code>.travis.yml</code> into it.</p>
<h1 id="powershellandbashmixture">PowerShell and BASH mixture</h1>
<p>The first idea was to just re-use the Windows PowerShell scripts and the Linux BASH scripts and call in from one YAML.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/migrate-travis-to-appveyor-ps-and-sh.png" alt="migrate-travis-to-appveyor-ps-and-sh"></p>
<p>Hm, now the <code>appveyor.yml</code> looked messy. You can tell with <code>ps:</code> that you want to run PowerShell, with <code>sh:</code> you can choose BASH.</p>
<p>With the environment variable <code>APPVEYOR_YML_DISABLE_PS_LINUX: true</code> you can turn off PowerShell support for Linux.</p>
<p>But it really looked ugly.</p>
<h1 id="powershellonlinuxreally">PowerShell on Linux, really?</h1>
<p>Microsoft has announced PowerShell support on Linux months ago. But I only smiled upto now. What should I do with just another script language on Linux, I thought? It only made sense when you come from Windows and don't want to learn BASH.</p>
<p>But looking at this mixed YAML mixture I thought: &quot;Hey, let's try PowerShell on Linux here&quot; to have a platform independent script.</p>
<p>I just edited the YAML file how it should look like.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/migrate-travis-to-appveyor-only-ps.png" alt="migrate-travis-to-appveyor-only-ps"></p>
<p>Much cleaner. Oh, what about these Unix slashes? But cool, they really work in PowerShell, even on Windows.</p>
<p>The only tricky part was integrating the Travis build matrix into the AppVeyor build matrix. My use-case is running one Windows build, but three Linux builds configured by an environment variable.</p>
<p>With some excludes (thanks to AppVeyor support) the YAML now looks like this</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/migrate-travsi-to-appveyor-excludes.png" alt="migrate-travsi-to-appveyor-excludes"></p>
<p>And hey, the build matrix in AppVeyor looked promising.</p>
<ul>
<li>Windows, amd64</li>
<li>Linux, arm</li>
<li>Linux, arm64</li>
<li>Linux, amd64</li>
</ul>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/appveyor-matrix-build.png" alt="appveyor-matrix-build"></p>
<p>The updated AppVeyor only CI pipeline now looks like this.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/appveyor-pipeline.png" alt="appveyor-pipeline"></p>
<p>The three Windows images are done in a different way. Once there are different Docker build agents to support 1709 and 1803 images I can move that to the build matrix as well.</p>
<h1 id="appveyoryml">appveyor.yml</h1>
<p>This is the <code>appveyor.yml</code> to define a matrix build for three Linux builds and one Windows build.</p>
<pre><code>version: 1.0.{build}
image:
- Visual Studio 2017
- Ubuntu

environment:
  matrix:
    - ARCH: arm
    - ARCH: arm64
    - ARCH: amd64

matrix:
  exclude:
    - image: Visual Studio 2017
      ARCH: arm
    - image: Visual Studio 2017
      ARCH: arm64

build_script:
  - ps: ./build.ps1

test_script:
  - ps: ./test.ps1

deploy_script:
  - ps: ./deploy.ps1
</code></pre>
<h1 id="buildps1">build.ps1</h1>
<p>The platform independent build script has the <code>docker build</code> command. As the <code>Dockerfile</code> differs for Windows I have to choose a different name as well add the build argument for the Linux build. But with the <code>$isWindows</code> variable you can easily check whether this script runs in the Windows agent or the Linux agent.</p>
<pre><code>$ErrorActionPreference = 'Stop';
Write-Host Starting build

if ($isWindows) {
  docker build --pull -t whoami -f Dockerfile.windows .
} else {
  docker build -t whoami --build-arg &quot;arch=$env:ARCH&quot; .
}

docker images
</code></pre>
<h1 id="testps1">test.ps1</h1>
<p>The platform independent test script skips the ARM images, I haven't tested QEMU in the Linux builder that could help to even run the ARM images in the x64 Linux build agent.</p>
<p>The test starts the container. We could add a Invoke-WebRequest call to check if the web server responds with 200 OK. But this test is enough for now.</p>
<pre><code>Write-Host Starting test

if ($env:ARCH -ne &quot;amd64&quot;) {
  Write-Host &quot;Arch $env:ARCH detected. Skip testing.&quot;
  exit 0
}

$ErrorActionPreference = 'SilentlyContinue';
docker kill whoamitest
docker rm -f whoamitest

$ErrorActionPreference = 'Stop';
Write-Host Starting container
docker run --name whoamitest -p 8080:8080 -d whoami
Start-Sleep 10

docker logs whoamitest

$ErrorActionPreference = 'SilentlyContinue';
docker kill whoamitest
docker rm -f whoamitest
</code></pre>
<h1 id="deployps1">deploy.ps1</h1>
<p>The platform independent deploy script first pushes each platform specific image from each build agent.</p>
<p>The last build agent in the matrix, it's the Linux amd64 variant, then creates the manifest list and also pushes the manifest list to Docker Hub.</p>
<p>It first stops if there is no tagged build. So only GitHub releases will be pushed to Docker Hub.</p>
<pre><code>$ErrorActionPreference = 'Stop';

if (! (Test-Path Env:\APPVEYOR_REPO_TAG_NAME)) {
  Write-Host &quot;No version tag detected. Skip publishing.&quot;
  exit 0
}
</code></pre>
<p>Then we define the Docker image name for the final Docker image (the manifest list, to be exact):</p>
<pre><code>$image = &quot;stefanscherer/whoami&quot;

Write-Host Starting deploy
</code></pre>
<h1 id="experimentalbatteriesincluded">(Experimental) batteries included</h1>
<p>To create the manifest list I use the Docker CLI to avoid downloading extra tools. But we have to enable experimental features in Docker CLI first:</p>
<pre><code>if (!(Test-Path ~/.docker)) { mkdir ~/.docker }
'{ &quot;experimental&quot;: &quot;enabled&quot; }' | Out-File ~/.docker/config.json -Encoding Ascii
</code></pre>
<p>I showed these experimental feature <a href="https://www.slideshare.net/stefscherer/azure-meetup-stuttgart-multiarch-docker-images">in several talks</a>. But here is a small overview. In addition to <code>docker push</code> - or <code>docker image push</code> there are two new commands: <code>docker manifest create</code> and <code>docker manifest push</code>:</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/docker-manifest-create-push.png" alt="docker-manifest-create-push"></p>
<p>For the next steps we need to be logged in with the Docker Hub account.</p>
<pre><code>docker login -u=&quot;$env:DOCKER_USER&quot; -p=&quot;$env:DOCKER_PASS&quot;
</code></pre>
<h1 id="pushtheplatformspecificimage">Push the platform specific image</h1>
<p>Now the script tags and pushes the platform specific Docker image with a correpsonding tag name.</p>
<pre><code>$os = If ($isWindows) {&quot;windows&quot;} Else {&quot;linux&quot;}
docker tag whoami &quot;$($image):$os-$env:ARCH-$env:APPVEYOR_REPO_TAG_NAME&quot;
docker push &quot;$($image):$os-$env:ARCH-$env:APPVEYOR_REPO_TAG_NAME&quot;
</code></pre>
<h1 id="windowsbuildrebasedockerimage">Windows build: rebase-docker-image</h1>
<p>For the Windows build I additionally run my <code>rebase-docker-image</code> tool. This is a hacker tool to replace the Windows base image from a given image with another version of the Windows base image. This works only in a few cases, but the whoami Golang binary and Dockerfile is safe for such hacks as this app really doesn't depend on the specific underlying base image. You can read more about that tool in my blog post <a href="https://stefanscherer.github.io/poc-build-images-for-1709-without-1709/">PoC: How to build images for 1709 without 1709</a>.</p>
<p>We create both a 1709 and 1803 variant as long as there is no AppVeyor build agent that is able to produce 'native' Docker builds for that.</p>
<pre><code>if ($isWindows) {
  # Windows
  Write-Host &quot;Rebasing image to produce 1709 variant&quot;
  npm install -g rebase-docker-image
  rebase-docker-image `
    &quot;$($image):$os-$env:ARCH-$env:APPVEYOR_REPO_TAG_NAME&quot; `
    -t &quot;$($image):$os-$env:ARCH-$env:APPVEYOR_REPO_TAG_NAME-1709&quot; `
    -b microsoft/nanoserver:1709

  Write-Host &quot;Rebasing image to produce 1803 variant&quot;
  npm install -g rebase-docker-image
  rebase-docker-image `
    &quot;$($image):$os-$env:ARCH-$env:APPVEYOR_REPO_TAG_NAME&quot; `
    -t &quot;$($image):$os-$env:ARCH-$env:APPVEYOR_REPO_TAG_NAME-1803&quot; `
    -b microsoft/nanoserver:1803

}
</code></pre>
<h1 id="linuxbuildcreateandpushmanifestlist">Linux build: Create and push manifest list</h1>
<p>The Linux amd64 build agent runs as the last one in the matrix build, so it's easy to create the manifest list. All platform specific Docker images are already pushed to Docker Hub.</p>
<p>We run <code>docker manifest create</code> and then <code>docker manifest push</code> for the target image name.</p>
<pre><code>else {
  # Linux
  if ($env:ARCH -eq &quot;amd64&quot;) {
    # The last in the build matrix
    docker -D manifest create &quot;$($image):$env:APPVEYOR_REPO_TAG_NAME&quot; `
      &quot;$($image):linux-amd64-$env:APPVEYOR_REPO_TAG_NAME&quot; `
      &quot;$($image):linux-arm-$env:APPVEYOR_REPO_TAG_NAME&quot; `
      &quot;$($image):linux-arm64-$env:APPVEYOR_REPO_TAG_NAME&quot; `
      &quot;$($image):windows-amd64-$env:APPVEYOR_REPO_TAG_NAME&quot; `
      &quot;$($image):windows-amd64-$env:APPVEYOR_REPO_TAG_NAME-1709&quot; `
      &quot;$($image):windows-amd64-$env:APPVEYOR_REPO_TAG_NAME-1803&quot;
    docker manifest annotate &quot;$($image):$env:APPVEYOR_REPO_TAG_NAME&quot; &quot;$($image):linux-arm-$env:APPVEYOR_REPO_TAG_NAME&quot; --os linux --arch arm --variant v6
    docker manifest annotate &quot;$($image):$env:APPVEYOR_REPO_TAG_NAME&quot; &quot;$($image):linux-arm64-$env:APPVEYOR_REPO_TAG_NAME&quot; --os linux --arch arm64 --variant v8
    docker manifest push &quot;$($image):$env:APPVEYOR_REPO_TAG_NAME&quot;

    Write-Host &quot;Pushing manifest $($image):latest&quot;
    docker -D manifest create &quot;$($image):latest&quot; `
      &quot;$($image):linux-amd64-$env:APPVEYOR_REPO_TAG_NAME&quot; `
      &quot;$($image):linux-arm-$env:APPVEYOR_REPO_TAG_NAME&quot; `
      &quot;$($image):linux-arm64-$env:APPVEYOR_REPO_TAG_NAME&quot; `
      &quot;$($image):windows-amd64-$env:APPVEYOR_REPO_TAG_NAME&quot; `
      &quot;$($image):windows-amd64-$env:APPVEYOR_REPO_TAG_NAME-1709&quot; `
      &quot;$($image):windows-amd64-$env:APPVEYOR_REPO_TAG_NAME-1803&quot;
    docker manifest annotate &quot;$($image):latest&quot; &quot;$($image):linux-arm-$env:APPVEYOR_REPO_TAG_NAME&quot; --os linux --arch arm --variant v6
    docker manifest annotate &quot;$($image):latest&quot; &quot;$($image):linux-arm64-$env:APPVEYOR_REPO_TAG_NAME&quot; --os linux --arch arm64 --variant v8
    docker manifest push &quot;$($image):latest&quot;
  }
}
</code></pre>
<h1 id="checktheresultingimage">Check the resulting image</h1>
<p>With the Docker image <code>mplatform/mquery</code> from Docker Captain Phil Estes you can inspect such multi-arch images.</p>
<pre><code>$ docker run --rm mplatform/mquery stefanscherer/whoami
Image: stefanscherer/whoami
 * Manifest List: Yes
 * Supported platforms:
   - linux/amd64
   - linux/arm/v6
   - linux/arm64/v8
   - windows/amd64:10.0.14393.2248
   - windows/amd64:10.0.16299.431
   - windows/amd64:10.0.17134.48
</code></pre>
<p>As you can see this image provides three Linux and three Windows variants. Windows can choose the best fit to the Windows kernel version to avoid running Windows Containers in Hyper-V mode.</p>
<p>Now try this image on any platform with</p>
<pre><code>docker run -d -p 8080:8080 stefanscherer/whoami
</code></pre>
<p>It will work on your Raspberry Pi, running <a href="https://blog.hypriot.com">HypriotOS</a> or manually installed Docker. It will work on any Linux cloud machine, it will work in Docker for Mac or Docker 4 Windows.</p>
<p>Then access the published port 8080 with a browser. You will see that it shows the container name and the OS and CPU architecture name of the compiled binary.</p>
<p>If you have a use-case for such a multi-arch / multi-os image and want to provide it to your community, <a href="https://github.com/StefanScherer/whoami">fork my GitHub repo</a> and also <a href="https://stefanscherer.github.io/fork-appveyor-buildpipeline/">fork the AppVeyor build pipeline</a>. It's really easy to get started.</p>
<p>I hope you enjoyed this blog post and I would be happy if you share it with your friends. I'm <a href="https://twitter.com/stefscherer">@stefscherer</a> on Twitter.</p>
</div>]]></content:encoded></item><item><title><![CDATA[How to build a forked GitHub repo: Spot the YAML]]></title><description><![CDATA[<div class="kg-card-markdown"><p>Maybe you find an interesting project on GitHub and want to build it your own. How can you do that? Maybe the project is written in a programming language that you are not familiar with. Or it uses a lot of tools to build that you don't have locally. Of</p></div>]]></description><link>https://stefanscherer.github.io/fork-appveyor-buildpipeline/</link><guid isPermaLink="false">5b12b403d71f9600016d99e8</guid><category><![CDATA[AppVeyor]]></category><category><![CDATA[GitHub]]></category><category><![CDATA[Docker Hub]]></category><category><![CDATA[Docker]]></category><dc:creator><![CDATA[Stefan Scherer]]></dc:creator><pubDate>Sat, 02 Jun 2018 16:45:00 GMT</pubDate><content:encoded><![CDATA[<div class="kg-card-markdown"><p>Maybe you find an interesting project on GitHub and want to build it your own. How can you do that? Maybe the project is written in a programming language that you are not familiar with. Or it uses a lot of tools to build that you don't have locally. Of course you have hear of Docker to put all build tools and dependencies into a container. But what if the project doesn't provide a Dockerfile?</p>
<p>Sometimes it is easier to just look at the repo. Does it have some green build badges in the <a href="http://README.md">README.md</a>? That is a good first hint that they use a CI pipeline. Look for YAML files that show you which CI service the project uses.</p>
<p>I'll show you an example with one of my GitHub repos. This project builds a Docker image with a simple web server, it's written in Golang, bla bla bla...<br>
The point is, there is a CI pipeline for AppVeyor and the corresponding YAML file also is in my repo. Let's have a look how you can fork my repo and fork the build pipeline.</p>
<h2 id="whatisappveyor">What is AppVeyor?</h2>
<p>The GitHub market place shows a lot of offerings for <a href="https://github.com/marketplace/category/continuous-integration">continuous integration</a>. This is what you normally want to have automatic tests for each Git commit or pull request you receive.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/appveyor.png" alt="appveyor"></p>
<p><a href="https://www.appveyor.com">AppVeyor</a> is my #1 place to go if I want Windows builds. It is really easy to attach it to your GitHub repo with a YAML file.</p>
<p>It can be as simple as this example <code>appveyor.yml</code> file.</p>
<pre><code>version: 1.0.{build}
image:
- Visual Studio 2017

build_script:
  - ps: ./build.ps1

test_script:
  - ps: ./test.ps1

deploy_script:
  - ps: ./deploy.ps1
</code></pre>
<h2 id="forkingbuildpipelines">Forking build pipelines</h2>
<p>What is the advantage to write a YAML file you may ask. Well I really like to share not only my code, but also my pipeline with the community. Others can fork my repo and only need a few clicks to attach the fork and have the complete pipeline up and running for themselves.</p>
<h1 id="whoamiexample">Whoami example</h1>
<p>In the next screenshots I will show you how easy it is to setup a build pipeline for a repo that you have seen the first time.</p>
<p>Go to the GitHub repo <a href="https://github.com/StefanScherer/whoami">https://github.com/StefanScherer/whoami</a>.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/github-whoami-repo.png" alt="GitHub StefanScherer/whoami repo"></p>
<p>You can fork it to your own GitHub account with the &quot;Fork&quot; button. GitHub will prepare the fork for you.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/github-forking-repo.png" alt="github forking repo"></p>
<p>Now scroll down to the <a href="http://README.md">README.md</a>. The next thing is to attach the pipeline to your fork.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/github-readme-link-to-appveyor.png" alt="github repo, go to readme and follow link to appveyor"></p>
<p>Just click on the the AppVeyor build badge to jump to the AppVeyor site, maybe open a new tab as we need the GitHub site later as well.<br>
Now you can see the build status of my repo. This is not your fork yet, but we now can sign in to AppVeyor.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/appveyor-buildstatus-upstream-repo.png" alt="appveyor buildstatus upstream repo, link to sign in"></p>
<p>Click on &quot;SIGN IN&quot; in the top right corner. AppVeyor will ask you how to sign in. Just use GitHub.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/appveyor-sign-in.png" alt="appveyor sign in with github"></p>
<p>Now GitHub will ask you if you want to give AppVeyor read-only access to your user data and public teams.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/appveyor-auth-login.png" alt="appveyor-auth-login"></p>
<p>After that you have connected AppVeyor to your account.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/appveyor-lets-start.png" alt="appveyor-lets-start"></p>
<p>Now this has to be done only once. After that you can add the forked repo to build on AppVeyor. Click on &quot;NEW PROJECT&quot; in the top left corner.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/appveyor-select-github-repo.png" alt="appveyor-select-github-repo"></p>
<p>You can choose between several version control systems. As you have forked a GitHub repo, click on &quot;GitHub&quot; and then on &quot;Authorize GitHub&quot;.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/appveyor-auth-github-repos.png" alt="appveyor-auth-github-repos"></p>
<p>AppVeyor needs some more access rights to add the Web hook for you and to send commit statuses. Click on &quot;Authorize appveyor&quot; to grant access.</p>
<p>Now you will see a list of GitHub repos of your GitHub account.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/appveyor-add-github-project.png" alt="appveyor-add-github-project"></p>
<p>Move to the &quot;whoami&quot; repo and click on the <strong>&quot;+ Add&quot;</strong> button on the right side. The UI isn't the best here, I often missed the Add link for my first projects.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/appveyor-github-repo-connected.png" alt="appveyor-github-repo-connected"></p>
<p>Congratulations! You have the build pipeline up and running. No VM's to setup, no installation required. You didn't have to clone the repo to your local machine yet.</p>
<p>Each Git commit will now trigger a build on AppVeyor with the <code>appveyor.yml</code> file that comes with the sources in the GitHub repo. You don't have to think what steps you have to do to build this project.</p>
<h2 id="adjustthefork">Adjust the fork</h2>
<h3 id="adjustreadmemd">Adjust <a href="http://README.md">README.md</a></h3>
<p>The first change should be to adjust the build badge in the <code>README.md</code> to link to your forked build.</p>
<p>Let's do that in the browser, so you still don't have to clone the repo to you local machine.</p>
<p>But first we have to grab the build badge link. Go to &quot;Settings&quot; and then to &quot;Badges&quot;. You will see some samples, pick the Sample Markdown code</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/appveyor-settings-badge-markdown.png" alt="appveyor-settings-badge-markdown"></p>
<p>Now head over to the GitHub browser tab and edit the <code>README.md</code> file.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/github-edit-readme.png" alt="github-edit-readme"></p>
<p>In this editor paste the new build badge link. Also adjust the Docker Hub badge to point to your desired Docker Hub image name. After that scroll down and commit the changes.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/github-commit-readme-changes.png" alt="github-commit-readme-changes"></p>
<p>Head back to AppVeyor and you will see your first build running.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/appveyor-first-build-running.png" alt="appveyor-first-build-running"></p>
<p>Isn't that fantastic? You just triggered a build from your browser. You can follow the build (it's a matrix build, we will have a closer look <a href="https://stefanscherer.github.io/use-appveyor-to-build-multi-arch-docker-image/">in the next blog post</a>).</p>
<p>After a while the build is green.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/Bildschirmfoto-2018-06-02-um-17.42.57.png" alt="Bildschirmfoto-2018-06-02-um-17.42.57"></p>
<h3 id="adjustdeployps1">Adjust deploy.ps1</h3>
<p>The second change in the forked repo is to adjust the Docker image name to deploy it to Docker Hub for when you start a GitHub release build.</p>
<p>Head over to GitHub browser tab and edit the <code>deploy.ps1</code> script.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/github-edit-deploy-ps1.png" alt="github-edit-deploy-ps1"></p>
<p>In line 8 you have to adjust the <code>$image</code> variable to fit your needs.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/github-commit-changes-deploy-ps1.png" alt="github-commit-changes-deploy-ps1"></p>
<p>After that commit the changes, a second build will be triggered. But nothing more happens in the second build.</p>
<h2 id="tellmeasecret">Tell me a secret</h2>
<p>The <code>appveyor.yml</code> is configured to deploy the Docker image only during a release build. For such releases AppVeyor needs access to your Docker registry you want to push to. In our case it's the Docker Hub.</p>
<p>This is done with secret environment variables. You can either use secrets in the <code>appveyor.yml</code> or just edit the environment variables in the AppVeyor browser tab. I'll show you the latter how to do it.</p>
<p>Go to &quot;SETTINGS&quot; and click the &quot;Environment&quot; tab. We need to add two environment variables</p>
<ul>
<li>DOCKER_USER</li>
<li>DOCKER_PASS</li>
</ul>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/appveyor-project-settings-environment.png" alt="appveyor-project-settings-environment"></p>
<p>Then scroll down and <strong>click on &quot;Save&quot;</strong>. This is the second thing that could be improved in the UI. You often don't see this &quot;Save&quot; button.</p>
<p>If you don't like to add your real Docker Hub account a good practise is to use another Docker Hub account for just the pushes and grant that account write access to only the Docker Hub images you want to.</p>
<h2 id="releaseit">Release it!</h2>
<p>Now, the build pipeline is set up in AppVeyor, as you have seen, the build and minimal tests were green. Now it's time to release the first Docker image.</p>
<p>Go to your forked GitHub repo again. There is a link to the &quot;releases&quot;. Click on &quot;releases&quot;.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/github-go-to-releases.png" alt="github-go-to-releases"></p>
<p>You have forked all the tags, but not the releases. Now let's &quot;Draft a new release&quot; to trigger a build.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/github-releases-draft-new-release.png" alt="github-releases-draft-new-release"></p>
<p>Use for example &quot;2.0.0&quot; as new release and tag name, enter some useful description.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/github-draft-release-2.png" alt="github-draft-release-2"></p>
<p>Then press &quot;Publish release&quot;. This also triggers a new build in AppVeyor, this time a tagged build.</p>
<p>In AppVeyor you can see the tag name &quot;2.0.0&quot;<br>
<img src="https://stefanscherer.github.io/content/images/2018/06/appveyor-release-build.png" alt="appveyor-release-build"></p>
<p>You now also can follow the build, but I'll explain it in more detail <a href="https://stefanscherer.github.io/use-appveyor-to-build-multi-arch-docker-image/">in the next blog post</a>. After some minutes the build is completed and green.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/appveyor-release-build-finished-1.png" alt="appveyor-release-build-finished-1"></p>
<p>Now, do we really have a Docker image pushed to Docker Hub? Let's check. Go back to your GitHub repo and check if the Docker Hub badge also works.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/github-dockerhub-badges.png" alt="github-dockerhub-badges"></p>
<p>And yes, there it is. You have successfully published a Docker image from an application you don't really have to understand the language or how to setup the build steps for that.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/dockerhub-whoami.png" alt="dockerhub-whoami"></p>
<p>That's the &quot;let me do it&quot; first approach. Now you have time to look at all the files. Start with the <code>appveyor.yml</code>, the YAML is the start of the build pipeline.</p>
<p>Or start with the application code which is written in Golang.</p>
<h1 id="tldrshareyouryaml">TL/DR: Share your YAML</h1>
<p>In this blog post you have seen how important it is to share not only the code, but also the build pipeline. You have learned to watch out for YAML files. There are other CI services out there, but the pattern is almost the same. Look for <code>.travis.yml</code>, <code>.circleci/config.yml</code> and similar names.</p>
<p>If you liked this blog post please share it with your friends. You can follow me on Twitter <a href="https://twitter.com/stefscherer">@stefscherer</a> as well.</p>
</div>]]></content:encoded></item><item><title><![CDATA[Ship happens. Secrets leaked to GitHub, what next?]]></title><description><![CDATA[<div class="kg-card-markdown"><p>What a wonderful day. I just changed some code in one of my weekend projects and then it happened. I totally screwed it up, I accidentally pushed some secrets to a GitHub pull request. Yes, ship happens. We're all humans and make mistakes. We normally blog about success, but I</p></div>]]></description><link>https://stefanscherer.github.io/ship-happens-secrets-leaked-to-github/</link><guid isPermaLink="false">5b1288ffd71f9600016d99e0</guid><category><![CDATA[GitHub]]></category><category><![CDATA[secrets]]></category><category><![CDATA[ubiquity]]></category><category><![CDATA[unify]]></category><dc:creator><![CDATA[Stefan Scherer]]></dc:creator><pubDate>Sat, 02 Jun 2018 13:15:26 GMT</pubDate><content:encoded><![CDATA[<div class="kg-card-markdown"><p>What a wonderful day. I just changed some code in one of my weekend projects and then it happened. I totally screwed it up, I accidentally pushed some secrets to a GitHub pull request. Yes, ship happens. We're all humans and make mistakes. We normally blog about success, but I use my mistake to talk about how to fix this and how to prevent it from happening in the future again.</p>
<h1 id="thebadmistake">The bad mistake</h1>
<p>Well, I edited some code of my flash script to flash Raspberry Pi SD cards. This tool can also inject configuration to boot your Pi without any manual interaction to a specified hostname, or add your WiFi settings so it can join your wireless network automatically.</p>
<p>I pushed some code to a work-in-progress pull request when I saw my mistake on GitHub:</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/my-pull-request.png" alt="OMG, my pull request shows my WiFi PSK"></p>
<p>WTF, how did I ... ?</p>
<p>Well, for convenience reasons I kept a configuration file in the repo to easily flash a new SD card image with WiFi settings. And I can't really remember, but I eventually typed <code>git add .</code> and <code>git push</code> some minutes ago without recognising that this was a really, really bad idea.</p>
<h1 id="panicwhatnext">Panic, what next?</h1>
<p>I immediatelly went to my Ubiquity Cloud controller and changed the Wireless Network Security Key.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/unify2.png" alt="Unify Wireless Network settings"></p>
<p>But that was the next mistake. OK, I've changed the security key. But after a moment I realized that I also have some unattended boxes lying around in my house that use the old key to connect to my WiFi. My AirPort Express boxes for example are connected wirelessly.</p>
<h2 id="calmdownthinkandorganize">Calm down, think, and organize</h2>
<p>OK, changing the Security Key as first step is probably not the best idea. I don't want to run to each box with a patch cable to reconfigure it. Instead I've changed the key back to the old, compromised one and reconfigured all my wireless devices that I can reach through WiFi.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/airport1.png" alt="AirPort devices"></p>
<h2 id="reconfigurewirelessdevicesfirst">Reconfigure wireless devices first</h2>
<p>The devices with the dotted lines are connected through WiFi. Edit the wireless network password with the AirPort app on your Mac.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/airport2.png" alt="Change AirPort wireless network password"></p>
<p>After that change they will drop out of WiFi as they now have the new, but not actually working password.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/airport-unreachable.png" alt="AirPort devices unreachable"></p>
<p>Repeat that for all devices and think of other wireless devices that you can update without climbing up ladders or other hidden places.</p>
<h2 id="changeyourwifisecuritykey">Change your WiFi security key</h2>
<p>After that I changed the wireless security key in the Unify cloud controller. Save the new WiFi key in your password manager, I use 1Password</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/uniqif-change-security-key2.png" alt="Change wireless security key in Unify cloud controller"></p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/1password-1.png" alt="Update key in 1Password password manager"></p>
<p>After reconnecting to the new and now secure WiFi with the updated key I thought of the next steps. OK, the whole family has to update their smartphones and tables to connect to the WiFi again. That is managable. Now I'm coming to the next phase.</p>
<h1 id="cleaningup">Cleaning up</h1>
<p>The next steps was to clean up the pull request to get rid of the accidentally added files. You might think when you are quick nobody has seen your change and you can skip changing your WiFi secret at all. I'll prove you wrong in the next few minutes.</p>
<p>First I commented on my mistake to laugh at it, that's just relieving.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/github-pr-leak.png" alt="Comment your mistake on GitHub"></p>
<h2 id="removefilesremovecommits">Remove files, remove commits</h2>
<p>Now it's time to clean up the pull request branch and remove the unwanted files. We could just do <code>git rm wifi.yml</code>, but this will be added as a new commit to Git. Git has a history of each commit. I also want to get rid of these old commits.</p>
<p>These were my steps to cleanup the pull request branch.</p>
<p>I first squashed the pull request to one commit.</p>
<pre><code>git rebase -i $(git merge-base $(git rev-parse --abbrev-ref HEAD) master)
</code></pre>
<p>Then in the editor just <code>pick</code> the first commit and change all other commits to <code>squash</code>.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/git-squash.png" alt="git squash"></p>
<p>Now I have only one commit. This commit can be easily undone with</p>
<pre><code>git reset HEAD~1
</code></pre>
<p>Then add your secret files to the <code>.gitignore</code> file and add everything and commit it again.</p>
<p>Now your local pull request branch has only the files wanted in one single commit. But GitHub still stores the secret files. With the next command we'll fix that.</p>
<h2 id="gitpushf">git push -f</h2>
<p>When things went bad sometimes a <code>git push -f</code> is needed. But beware: This will overwrite the history in your Git repo. You really have to know what are you doing here. Don't use <code>git push -f</code> in a panic. Calm down first. Otherwise you will make it even worse.</p>
<p>But to remove the unwanted commits you need to overwrite the pull request branch.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/git-push-f-pr.png" alt="Dangerous: git push -f"></p>
<pre><code>git push -f origin add-version 
</code></pre>
<h2 id="everythingconcealednoway">Everything concealed? No way</h2>
<p>When you now look at the GitHub pull request you might think that every secret vanished and it's safe to keep the old WiFi password. No, GitHub has an incredible database, don't think that that this information was removed.</p>
<p>Each pull request can be commented and even after a <code>git push -f</code> some of the comments got outdated on source that no longer exist. But this is still visible and retrievable.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/github-show-outdated-1.png" alt="GitHub show outdated comments"></p>
<p>Look closer, there is a &quot;Show outdated&quot; link. You can open this</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/github-show-outdated-2.png" alt="GitHub show outdated comments still visible"></p>
<p>So whenever such a data breach happens, be prepared to change your secrets. <strong>If it hurts, do it more often.</strong></p>
<h1 id="understandingthecause">Understanding the cause</h1>
<p>After all this disaster recovery and cleanup there is still something to learn. What was the root cause and how can I prevent to make the same mistake again?</p>
<h2 id="gitadd">git add .</h2>
<p>The <code>git add .</code> command adds all modified and also untracked files and <code>git push</code> pushes all this code to GitHub into your already open pull request branch.<br>
Yes, I'm lazy and often commit everything as I'm normally work on one thing in a project.</p>
<p>I normally recognize such secret files from adding them, but as I realised the hard way is that you will type <code>git add .</code> at some point in a hurry without even recognizing it.</p>
<p>I scrolled up my terminal and found the situation where everything went wrong very soon.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/06/git-untracked-files.png" alt="Git repo with untracked files"></p>
<p>This is a bad smell having untracked files.</p>
<p>What can this be fixed?</p>
<ul>
<li>Learn to not use <code>git add .</code>. I don't think that will work as I'm trained to type this and it's hard to break a habit.</li>
<li>Maybe prevent <code>git add .</code>?, see <a href="https://stackoverflow.com/questions/25884007/disable-git-add-command">Stack Overflow</a> I'm not going this hard way.</li>
<li>Don't leave untracked files in your repo, yeah that sounds better.</li>
<li>Add local secret files to your <code>.gitignore</code> file. So a <code>git add .</code> is harmless.</li>
<li>Don't create such local secret files at all. Well you want something automated and just need config files with secrets.</li>
<li>Create local files without the secrets and inject secrets on the fly. That also sounds like a good plan.</li>
</ul>
<p>I'll look closer into the last idea to inject secrets on the fly. Don't leave secrets unprotected on your harddrive. Use command line interfaces for your password managers.</p>
<ul>
<li>Use <code>pass</code> - <a href="https://www.passwordstore.org">Pass: The Standard Unix Password Manager</a> that keeps secrets in GPG encrypted files which are also under version control in a separate Git repo.</li>
<li>I'll also have a look at the <a href="https://stefanscherer.github.io/ship-happens-secrets-leaked-to-github/(https://support.1password.com/command-line/)">1Password command line tool</a> <code>op</code>.</li>
</ul>
<p>You cannot change the past, you only can learn to make it better in the future.</p>
<p>I hope you find this blog post useful and I love to hear your feedback and experience about similar mistakes or better tips how to protect yourself from doing mistakes. Just drop a comment below or ping me on Twitter <a href="https://twitter.com/stefscherer">@stefscherer</a>.</p>
</div>]]></content:encoded></item><item><title><![CDATA[How to find dependencies of containerized Windows apps]]></title><description><![CDATA[<div class="kg-card-markdown"><p>Running applications in Windows containers keeps your server clean. The container image must contain all the dependencies that the application needs to run, for example all its DLL's. But sometimes it's hard to figure out why an application doesn't run in a container. Here's my way to find out what's</p></div>]]></description><link>https://stefanscherer.github.io/find-dependencies-in-windows-containers/</link><guid isPermaLink="false">5a84a3660f689f0001bafe61</guid><category><![CDATA[windows-containers]]></category><category><![CDATA[Docker]]></category><category><![CDATA[Hyper-V]]></category><category><![CDATA[process-monitor]]></category><category><![CDATA[sysinternals]]></category><dc:creator><![CDATA[Stefan Scherer]]></dc:creator><pubDate>Wed, 14 Feb 2018 23:01:47 GMT</pubDate><content:encoded><![CDATA[<div class="kg-card-markdown"><p>Running applications in Windows containers keeps your server clean. The container image must contain all the dependencies that the application needs to run, for example all its DLL's. But sometimes it's hard to figure out why an application doesn't run in a container. Here's my way to find out what's missing.</p>
<h1 id="processmonitor">Process Monitor</h1>
<p>To find out what's going on in a Windows Container I often use the <a href="https://sysinternals.com">Sysinternals</a> Process Monitor. It can capture all major syscalls in Windows such as file activity, starting processes, registry and networking activity.</p>
<p>But how can we use procmon to monitor inside a Windows container?</p>
<p>Well, I heard today that you can run procmon from command line to start and stop capturing events. I tried <a href="https://github.com/StefanScherer/dockerfiles-windows/tree/master/procmon">running procmon in a Windows container</a>, but it doesn't work correctly at the moment.</p>
<p>So the next possibilty is to run procmon on the container host.</p>
<p>On Windows 10 you only have Hyper-V containers. These are &quot;black boxes&quot; from your host operating system. The Process Monitor cannot look inside Hyper-V containers.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/02/procmon_windows10_hyperv_container.png" alt="procmon_windows10_hyperv_container"></p>
<p>To investigate a Windows container we need the &quot;normal&quot; Windows containers without running in Hyper-V isolation. The best solution I came up with is to run a Windows Server 2016 VM and install Process Monitor inside that VM.</p>
<p>When you run a Windows container you can see the container processes in the Task Manager of the Server 2016 VM. And Process Monitor can also see what these processes are doing. We have made some containers out of &quot;glass&quot; to look inside.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/02/procmon_windows_container_glass.png" alt="procmon_windows_container_glass"></p>
<h1 id="examplepostgresql">Example: PostgreSQL</h1>
<p>Let's try this out and put the PostgreSQL database server into a Windows container.</p>
<p>The following <code>Dockerfile</code> downloads the ZIP file of PostgreSQL 10.2, extracts all files and removes the ZIP file again.</p>
<pre><code># escape=`
FROM microsoft/windowsservercore:10.0.14393.2007 AS download

SHELL [&quot;powershell&quot;, &quot;-Command&quot;, &quot;$ErrorActionPreference = 'Stop'; $ProgressPreference = 'SilentlyContinue';&quot;]

ENV PG_VERSION 10.2-1

RUN Invoke-WebRequest $('https://get.enterprisedb.com/postgresql/postgresql-{0}-windows-x64-binaries.zip' -f $env:PG_VERSION) -OutFile 'postgres.zip' -UseBasicParsing ; `
    Expand-Archive postgres.zip -DestinationPath C:\ ; `
    Remove-Item postgres.zip
</code></pre>
<p>Now build and run a first container to try out the <code>postgres.exe</code> inside the container.</p>
<pre><code>docker build -t postgres .
docker run -it postgres cmd
</code></pre>
<p>Navigate into <code>C:\pgsql\bin</code> folder and run <code>postgres.exe -h</code>.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/02/postgres-nooutput.png" alt="postgres no output"></p>
<p>As you can see, nothing happens. No output. You just are back to the CMD prompt.</p>
<p>Now it's time to install <code>procmon.exe</code> on the container host and run it.</p>
<p>Open a PowerShell terminal in your Windows Server 2016 VM and run</p>
<pre><code>iwr -usebasicparsing https://live.sysinternals.com/procmon.exe -outfile procmon.exe
</code></pre>
<p><img src="https://stefanscherer.github.io/content/images/2018/02/install-procmon.png-shadow.png" alt="install procmon"></p>
<p>Now run <code>procmon.exe</code> and define a filter to see only file activity looking for DLL files and start capturing.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/02/procmon-filter.png-shadow.png" alt="define procmon filter"></p>
<p>I have a prepared filter available for download: <a href="https://github.com/StefanScherer/dockerfiles-windows/raw/master/procmon/depends.PMF">depends.PMF</a><br>
Go to <strong>Filter</strong>, then <strong>Organize Filters...</strong> and then <strong>Import...</strong></p>
<p>Now in your container run <code>postgres.exe -h</code> again.</p>
<p>As you can see Process Monitor captures file access to <code>\Device\Harddisk\VolumeXX\psql\bin\</code> which is a folder in your container.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/02/procmon-postgres.png-shadow.png" alt="procmon postgres capture"></p>
<p>The interesting part is which DLL's cannot be found here. The <code>MSVCR120.dll</code> is missing, the Visual Studio Runtime DLL's.</p>
<p>For other applications you might have to look for config files or folders that are missing that stops your app from running in a Windows container.</p>
<p>Let's append the missing runtime in the <code>Dockerfile</code> with the next few lines:</p>
<pre><code>RUN Invoke-WebRequest 'http://download.microsoft.com/download/0/5/6/056DCDA9-D667-4E27-8001-8A0C6971D6B1/vcredist_x64.exe' -OutFile vcredist_x64.exe ; `
    Start-Process vcredist_x64.exe -ArgumentList '/install', '/passive', '/norestart' -NoNewWindow -Wait ; `
    Remove-Item vcredist_x64.exe
</code></pre>
<p>Build the image and run another container and see if it works now.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/02/postgres-usage.png" alt="postgres usage"></p>
<p>Yes, this time we see the <code>postgres.exe</code> usage, so it seems we have solved all our dependency problems.</p>
<h1 id="gonanoserver">Go NanoServer</h1>
<p>Now we have a Windows Server Core image with PostgreSQL server. The image size is now 11.1GByte. Let's go one step further and make it a much smaller NanoServer image.</p>
<p>In NanoServer we cannot run MSI packages or vcredist installers, and soon there is also no PowerShell. But with a so called <strong>multi-stage build</strong> it's easy to <code>COPY</code> deploy the PostgreSQL binaries and dependencies into a fresh NanoServer image.</p>
<p>We append some more lines to our <code>Dockerfile</code>. Most important line is the second <code>FROM</code> line to start a new stage with the smaller NanoServer image.</p>
<pre><code>FROM microsoft/nanoserver:10.0.14393.2007
</code></pre>
<p>Then we <code>COPY</code> the <code>pgsql</code> folder from the first stage into the NanoServer image, as well as the important runtime DLL's.</p>
<pre><code>COPY --from=download /pgsql /pgsql
COPY --from=download /windows/system32/msvcp120.dll /pgsql/bin/msvcp120.dll
COPY --from=download /windows/system32/msvcr120.dll /pgsql/bin/msvcr120.dll
</code></pre>
<p>Set the <code>PATH</code> variable to have all tools accessible, expose the standard port and define a command.</p>
<pre><code>RUN setx /M PATH &quot;C:\pgsql\bin;%PATH%&quot;

EXPOSE 5432
CMD [&quot;postgres&quot;]
</code></pre>
<p>Now build the image again and try it out with</p>
<pre><code>docker run postgres postgres.exe --help
</code></pre>
<p><img src="https://stefanscherer.github.io/content/images/2018/02/docker-run-postgres-nano.png" alt="docker run postgres in nano"></p>
<p>We still see the usage, so the binaries also work fine in NanoServer. The final postgres images is down at 1.64GByte.<br>
If you do this with a NanoServer 1709 or Insider image the sizes is even smaller at 738MByte. You can have a look at the compressed sizes on the Docker Hub at <a href="https://hub.docker.com/r/stefanscherer/postgres-windows/tags/">stefanscherer/postgres-windows</a>.</p>
<h1 id="conclusion">Conclusion</h1>
<p>Process Monitor can help you find issues that prevent applications to run properly in Windows containers. Run it from a Server 2016 container host to observe your or a foreign application.</p>
<p>I hope you find this blog post useful and I love to hear your feedback and experience about Windows containers. Just drop a comment below or ping me on Twitter <a href="https://twitter.com/stefscherer">@stefscherer</a>.</p>
</div>]]></content:encoded></item><item><title><![CDATA[Terraforming a Windows Insider Server in Azure]]></title><description><![CDATA[<div class="kg-card-markdown"><p>There may be different ways to run the Windows Insider Server Preview builds in Azure. Here's my approach to run a Windows Docker engine with the latest Insider build.</p>
<h2 id="buildtheazurevm">Build the Azure VM</h2>
<p>On your local machine clone the <a href="https://github.com/StefanScherer/packer-windows">packer-windows</a> repo which has a Terraform template to build an Azure</p></div>]]></description><link>https://stefanscherer.github.io/terraforming-a-windows-insider-server-in-azure/</link><guid isPermaLink="false">5a64f348845d55000179abc4</guid><category><![CDATA[Azure]]></category><category><![CDATA[Docker]]></category><category><![CDATA[windows-containers]]></category><category><![CDATA[Insider]]></category><category><![CDATA[Windows]]></category><category><![CDATA[Terraform]]></category><category><![CDATA[Vagrant]]></category><category><![CDATA[Packer]]></category><dc:creator><![CDATA[Stefan Scherer]]></dc:creator><pubDate>Sun, 21 Jan 2018 21:32:41 GMT</pubDate><content:encoded><![CDATA[<div class="kg-card-markdown"><p>There may be different ways to run the Windows Insider Server Preview builds in Azure. Here's my approach to run a Windows Docker engine with the latest Insider build.</p>
<h2 id="buildtheazurevm">Build the Azure VM</h2>
<p>On your local machine clone the <a href="https://github.com/StefanScherer/packer-windows">packer-windows</a> repo which has a Terraform template to build an Azure VM. The template chooses a V3 machine which is able to run nested VM's.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/01/insider_in_azure_terraform_apply.png" alt="Create a VM in Azure with Terraform"></p>
<p>You need <a href="https://terraform.io">Terraform</a> on your local machine which can be installed with a package manager.</p>
<p>Mac:</p>
<pre><code>brew install terraform
</code></pre>
<p>Windows:</p>
<pre><code>choco install terraform
</code></pre>
<p>Now clone the GitHub repo and go to the template.</p>
<pre><code>git clone https://github.com/StefanScherer/packer-windows
cd packer-windows/nested/terraform
</code></pre>
<p>Adjust the <code>variables.tf</code> file with resource group name, account name and password, region and other things. You also need some information for Terraform to create resources in your Azure account. Please read the <a href="https://www.terraform.io/docs/providers/azurerm/">Azure Provider</a> documentation for details how to obtain these values.</p>
<pre><code>export ARM_SUBSCRIPTION_ID=&quot;uuid&quot;
export ARM_CLIENT_ID=&quot;uuid&quot;
export ARM_CLIENT_SECRET=&quot;uuid&quot;
export ARM_TENANT_ID=&quot;uuid&quot;

terraform apply
</code></pre>
<p>This command will take some minutes until the VM is up and running. It also runs a provision script to install further tools for you.</p>
<h2 id="rdpintothepackerbuildervm">RDP into the Packer builder VM</h2>
<p>Now log into the Azure VM with a RDP client. This VM has Hyper-V installed as well as Packer and Vagrant, the tools we will use next.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/01/insider_in_azure_packer_build_vagrant_up.png" alt="Run Packer and Vagrant in Azure VM"></p>
<h2 id="buildtheinsidervm">Build the Insider VM</h2>
<p>The next step is to build the Windows Insider Server VM. We will use <a href="https://packer.io">Packer</a> for the task. This produces a Vagrant box file that can be re-used locally on a Windows 10 machine.</p>
<p>Clone the packer-windows repo and run the Packer build with the manually downloaded Insider ISO file.</p>
<pre><code>git clone https://github.com/StefanScherer/packer-windows
cd packer-windows

packer build --only=hyperv-iso --var iso_url=~/Downloads/Windows_InsiderPreview_Server_2_17074.iso windows_server_insider_docker.json
</code></pre>
<p>This command will take some minutes as it also downloads the Insider Docker images to have them cached when you start a new VM.</p>
<p>Add the box file so it can be used by Vagrant.</p>
<pre><code>vagrant box add windows_server_insider_docker windows_server_insider_docker_hyperv.box
</code></pre>
<h2 id="boottheinsidervm">Boot the Insider VM</h2>
<p>Now we're using <a href="https://vagrantup.com">Vagrant</a> to boot the Insider VM. I'll use my <a href="https://github.com/StefanScherer/windows-docker-machine">windows-docker-machine</a> Vagrant template which I also use locally on a Mac or Windows 10 laptop.</p>
<pre><code>git clone https://github.com/StefanScherer/windows-docker-machine
cd windows-docker-machine
vagrant plugin install vagrant-reload

vagrant up --provider hyperv insider
</code></pre>
<p>This will spin up a VM and creates TLS certificates for the Docker engine running in the Windows Insider Server VM.</p>
<p>You could use it from the Azure VM, but we want to make the nested VM reachable from our laptop.</p>
<p>Now retrieve the IP address of this nested VM to add some port mappings so we can access the nested VM from our local machine.</p>
<pre><code>vagrant ssh-config
</code></pre>
<p>Use the IP address shown for the next commands, eg. 192.168.0.10</p>
<pre><code>netsh interface portproxy add v4tov4 listenport=2376 listenaddress=0.0.0.0 connectport=2376 connectaddress=192.168.0.10
netsh interface portproxy add v4tov4 listenport=9000 listenaddress=0.0.0.0 connectport=9000 connectaddress=192.168.0.10
netsh interface portproxy add v4tov4 listenport=3390 listenaddress=0.0.0.0 connectport=3389 connectaddress=192.168.0.10
</code></pre>
<h2 id="createdockertlsforexternaluse">Create Docker TLS for external use</h2>
<p>As we want to access this Docker engine from our local laptop we have to re-create the TLS certs with the FQDN of the Azure VM.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/01/insider_in_azure_rdp.png" alt="RDP to Azure and nested VM"></p>
<p>Now RDP into the nested VM through port 3390 from your laptop.</p>
<p>You will see a CMD terminal. Run <code>powershell</code> to enter a PowerShell terminal.</p>
<p>Run the <code>create-machine.ps1</code> provision script again with the IP address and the FQDN of the Azure VM. Also specify the path of your local home directory (in my case <code>-machineHome /Users/stefan</code>) to make the docker-machine configuration work.</p>
<pre><code>C:\Users\demo\insider-docker-machine\scripts\create-machine.ps1 -machineHome /Users/stefan -machineName az-insider -machineIp 1.2.3.4 -machineFqdn az-insider-01.westeurope.cloudapp.azure.com
</code></pre>
<h2 id="rundockercontainers">Run Docker containers</h2>
<p>You can copy the generated TLS certificates from the nested VM through the RDP session back to your home directory in <code>$HOME/.docker/machine/machines</code> folder.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/01/insider_in_azure-1.png" alt="insider_in_azure-1"></p>
<p>Then you can easily switch the Docker environment variables locally on your</p>
<p>Mac:</p>
<pre><code>eval $(docker-machine env az-insider)
</code></pre>
<p>or Windows:</p>
<pre><code>docker-machine env az-insider | iex
</code></pre>
<p>Now you should be able to run Docker commands like</p>
<pre><code>docker images
docker run -it microsoft/nanoserver-insider cmd
</code></pre>
<h1 id="conclusion">Conclusion</h1>
<p>We have used a lot of tools to create this setup. If you do this only once it seems to be more step than needed. But keep in mind the Insider builds are shipped regularly so you will do some steps again and again.</p>
<p>To repeat some of these steps tools like Packer and Vagrant can help you go faster building VM's as Docker helps you go faster to ship your apps.</p>
<ul>
<li>Packer helps you repeat building a VM from new ISO.</li>
<li>Vagrant helps you repeat booting fresh VMs. Destroy early and often. Rebuild is cheap.</li>
<li>Docker helps you repeat creating and running applications.</li>
</ul>
<p>If you have another approach to run Insider builds in Azure please let me know. I love to hear your story. Please use the comments below if you have questions or want to share your setup.</p>
<p>If you liked this blog post please share it with your friends. You can follow me on Twitter <a href="https://twitter.com/stefscherer">@stefscherer</a> to stay updated with Windows containers.</p>
</div>]]></content:encoded></item><item><title><![CDATA[A sneak peek at LCOW]]></title><description><![CDATA[<div class="kg-card-markdown"><p>Last week a major <a href="https://github.com/moby/moby/pull/34859">pull request</a> to support Linux Containers on Windows (LCOW) has landed in master branch of the Docker project. With that feature enabled you will be able to run <strong>both Linux and Windows containers side-by-side</strong> with a single Docker engine.</p>
<p>So let's have a look how a</p></div>]]></description><link>https://stefanscherer.github.io/sneak-peek-at-lcow/</link><guid isPermaLink="false">5a64a75ee5611a0001acf91f</guid><category><![CDATA[Docker]]></category><category><![CDATA[LCOW]]></category><category><![CDATA[Linux]]></category><category><![CDATA[Windows 10]]></category><dc:creator><![CDATA[Stefan Scherer]]></dc:creator><pubDate>Sun, 21 Jan 2018 15:30:58 GMT</pubDate><content:encoded><![CDATA[<div class="kg-card-markdown"><p>Last week a major <a href="https://github.com/moby/moby/pull/34859">pull request</a> to support Linux Containers on Windows (LCOW) has landed in master branch of the Docker project. With that feature enabled you will be able to run <strong>both Linux and Windows containers side-by-side</strong> with a single Docker engine.</p>
<p>So let's have a look how a Windows 10 developer machine will look like in near future.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/01/lcow-marked.jpg" alt="LCOW on Windows 10"></p>
<ul>
<li>The Docker command <code>docker ps</code> lists all your running Linux and Windows containers.</li>
<li>You can use volumes to share data between containers and the host.</li>
<li>The containers can talk to each other over the container networks.</li>
<li>You can publish ports to your host and use localhost. But wait, this is still a Windows Insider feature coming to Windows 10 1803 release.</li>
</ul>
<h2 id="runninglinuxcontainers">Running Linux containers</h2>
<p>At the moment you need to specify the <code>--platform</code> option to pull Linux images. This option is also needed when the specific Docker images is a multi-arch image for both Linux and Windows.</p>
<pre><code>docker pull --platform linux alpine
</code></pre>
<p>Once you have pulled Linux images you can run them without the <code>--platform</code> option.</p>
<pre><code>docker run alpine uname -a
</code></pre>
<p>To allow Windows run Linux containers a small Hyper-V VM is needed. The LinuxKit project provides an image for LCOW at <a href="https://github.com/linuxkit/lcow">https://github.com/linuxkit/lcow</a>.</p>
<h1 id="sharedvolumes">Shared volumes</h1>
<p>Let's see how containers of different platforms can share data in a simple way. You can bind mount a volume into Linux and Windows containers.</p>
<p><img src="https://stefanscherer.github.io/content/images/2018/01/lcow-in-action.gif" alt="LCOW in action with shared volumes"></p>
<p>The following example shares a folder from the host with a Linux and Windows container.</p>
<p>First create a folder on the Windows 10 host:</p>
<pre><code>cd \
mkdir host
</code></pre>
<h3 id="runalinuxcontainer">Run a Linux container</h3>
<p>On the Windows 10 host run a Linux container and bind mount the folder as <code>/test</code> in the Linux container.</p>
<pre><code>docker run -it -v C:\host:/test alpine sh
</code></pre>
<p>In the Linux container create a file in that mounted volume.</p>
<pre><code>uname -a &gt; test/hello-from-linux.txt
</code></pre>
<h3 id="runawindowscontainer">Run a Windows container</h3>
<p>On the Windows 10 host run a Windows container and bind mount the folder as <code>C:\test</code> in the Windows container.</p>
<pre><code>docker run -i -v C:\host:C:\test microsoft/nanoserver:1709 cmd
</code></pre>
<p>In the Windows container create a file in that mounted volume.</p>
<pre><code>ver &gt; test\hello-from-windows.txt
</code></pre>
<h3 id="result">Result</h3>
<p>On the Windows 10 host list the files in the shared folder</p>
<pre><code>PS C:\&gt; dir host


    Directory: C:\host


Mode                LastWriteTime         Length Name
----                -------------         ------ ----
-a----        1/21/2018   4:32 AM             85 hello-from-linux.txt
-a----        1/21/2018   4:33 AM             46 hello-from-windows.txt
</code></pre>
<p>This is super convenient for development environments to share configuration files or even source code.</p>
<h1 id="draftingmixedworkloads">Drafting mixed workloads</h1>
<p>With Docker Compose you can spin up a mixed container environment. I just did these first steps to spin up a Linux and Windows web server.</p>
<pre><code class="language-yaml">version: &quot;3.2&quot;

services:

  web1:
    image: nginx
    volumes:
      - type: bind
        source: C:\host
        target: /test
    ports:
      - 80:80

  web2:
    image: stefanscherer/hello-dresden:0.0.3-windows-1709
    volumes:
      - type: bind
        source: C:\host
        target: C:\test
    ports:
      - 81:3000

networks:
  default:
    external:
      name: nat
</code></pre>
<p>Think of a Linux database and a Window front end, or vice versa...</p>
<h1 id="buildyourownlcowtestenvironment">Build your own LCOW test environment</h1>
<p>If you want to try LCOW yourself I suggest to spin up a fresh Windows 10 1709 VM.</p>
<h2 id="azure">Azure</h2>
<p>I have tested LCOW with a Windows 10 1709 VM in Azure. Choose a V3 machine to have nested hypervisor which you will need to run Hyper-V containers.</p>
<h3 id="containersandhyperv">Containers and Hyper-V</h3>
<p>Enable the Containers feature and Hyper-V feature:</p>
<pre><code>Enable-WindowsOptionalFeature -Online -FeatureName containers -All -NoRestart
Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All -NoRestart
</code></pre>
<h3 id="linuxkit">LinuxKit</h3>
<p>Now install the LinuxKit image for LCOW. I have catched the latest from a CircleCI artifact, but soon there will be a new release in the <a href="https://github.com/linuxkit/lcow/releases">linuxkit/lcow</a> repo.</p>
<pre><code>Invoke-WebRequest -OutFile &quot;$env:TEMP\linuxkit-lcow.zip&quot; &quot;https://23-111085629-gh.circle-artifacts.com/0/release.zip&quot;
Expand-Archive -Path &quot;$env:TEMP\linuxkit-lcow.zip&quot; -DestinationPath &quot;$env:ProgramFiles\Linux Containers&quot; -Force
</code></pre>
<h3 id="dockernightlybuild">Docker nightly build</h3>
<p>Now download and install the Docker engine. As this pull request only landed in master branch we have to use the nightly build for now.</p>
<pre><code>Invoke-WebRequest -OutFile &quot;$env:TEMP\docker-master.zip&quot; &quot;https://master.dockerproject.com/windows/x86_64/docker.zip&quot;
Expand-Archive -Path &quot;$env:TEMP\docker-master.zip&quot; -DestinationPath $env:ProgramFiles -Force
</code></pre>
<p>The next command installs the Docker service and enables the experimental features.</p>
<pre><code>. $env:ProgramFiles\docker\dockerd.exe --register-service --experimental
</code></pre>
<p>Set the PATH variable to have the Docker CLI available.</p>
<pre><code>[Environment]::SetEnvironmentVariable(&quot;Path&quot;, $env:Path + &quot;;$($env:ProgramFiles)\docker&quot;, [EnvironmentVariableTarget]::Machine)
</code></pre>
<p>Now reboot the machine to finish the Containers and Hyper-V installation. After the reboot the Docker engine should be up and running and the Docker CLI can be used from the PowerShell terminal.</p>
<h2 id="localvagrantenvironment">Local Vagrant environment</h2>
<p>If you have <a href="https://vagrantup.com">Vagrant</a> installed with Hyper-V or VMware as your hypervisor, you can spin up a local test environment with a few commands.</p>
<p>First clone my GitHub repo <a href="https://github.com/StefanScherer/docker-windows-box">docker-windows-box</a> which has a LCOW environment to play with.</p>
<pre><code>git clone https://github.com/StefanScherer/docker-windows-box
cd docker-windows-box
cd lcow
vagrant up
</code></pre>
<p>This will download the Vagrant base box if needed, spins up the Windows 10 VM and automatically installs all features shown above.</p>
<h1 id="conclusion">Conclusion</h1>
<p>With all these new Docker features coming to Windows in the next few months, Windows 10 is evolving to the most interesting developer platform in 2018.</p>
<p>Imagine what's possible: Use a <code>docker-compose.yml</code> to spin up a mixed scenario with Linux and Windows containers, live debug your app from Visual Studio Code, and much more.</p>
<p>If you liked this blog post please share it with your friends. You can follow me on Twitter <a href="https://twitter.com/stefscherer">@stefscherer</a> to stay updated with Windows containers.</p>
</div>]]></content:encoded></item><item><title><![CDATA[PoC: How to build images for 1709 without 1709]]></title><description><![CDATA[<div class="kg-card-markdown"><p>First of all: Happy Halloween! In this blog post you'll see some spooky things - or magic? Anyway I found a way to build Windows Docker images based on the new 1709 images without running on 1709. Sounds weird?</p>
<blockquote>
<p><strong>Disclaimer:</strong> The tools and described workflow to build such images on</p></blockquote></div>]]></description><link>https://stefanscherer.github.io/poc-build-images-for-1709-without-1709/</link><guid isPermaLink="false">59f90ee4f830c70001a9b8f1</guid><category><![CDATA[Docker]]></category><category><![CDATA[Windows Server 1709]]></category><category><![CDATA[windows-containers]]></category><category><![CDATA[AppVeyor]]></category><category><![CDATA[multi-arch]]></category><dc:creator><![CDATA[Stefan Scherer]]></dc:creator><pubDate>Tue, 31 Oct 2017 23:55:00 GMT</pubDate><content:encoded><![CDATA[<div class="kg-card-markdown"><p>First of all: Happy Halloween! In this blog post you'll see some spooky things - or magic? Anyway I found a way to build Windows Docker images based on the new 1709 images without running on 1709. Sounds weird?</p>
<blockquote>
<p><strong>Disclaimer:</strong> The tools and described workflow to build such images on old Windows Server versions may break at any time. It works for me and some special cases, but it does not mean it works for any other use-case.</p>
</blockquote>
<h2 id="the20161709gap">The 2016 &lt;-&gt; 1709 gap</h2>
<p>As you might know from my <a href="https://stefanscherer.github.io/docker-on-windows-server-1709/">previous blog post</a> there is a gap between the old and new Windows images. You cannot pull the new 1709 Docker images on current Windows Server 2016. This means you also cannot build images without updating your build machines to Windows Server 1709.</p>
<h2 id="appveyor">AppVeyor</h2>
<p>My favorite CI service for Windows is AppVeyor. They provide a Windows Server 2016 build agent with Docker and the latest base images installed. So it is very simple and convenient to build your Windows Docker images there. For example all my <a href="https://github.com/StefanScherer/dockerfiles-windows">dockerfiles-windows</a> Dockerfiles are built there and the images are pushed to Docker Hub.</p>
<p>I guess it will take a while until we can choose another build agent to start building for 1709 there.</p>
<p>But what should I do in the meantime?</p>
<ul>
<li>Should I build all 1709 images manually on a local VM?</li>
<li>Or spin up a VM in Azure? It is possible since today.</li>
</ul>
<p>But then I don't have the nice GitHub integration. And I have to do all the maintenance of a CI server (cleaning up disk space and so on) myself. Oh I don't want to go that way.</p>
<h2 id="dockerimageshavelayers">Docker images have layers</h2>
<p>Let's have a closer look at how a Docker image looks like. Each Docker image contains of one or more layers. Each layer is read-only. Any change will be done in a new layer on top of the underlying ones.</p>
<p>For example the Windows Docker image of a Node.js application looks more or less like this:</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/11/windows_image_layers-2.png" alt="windows_image_layers-2"></p>
<p>At the bottom you find the Windows base image, then we add the Node.js runtime. Then we can add our application code on top of that. This is how a Dockerfile works. Every FROM, RUN, ... is an extra layer.</p>
<p>Technically all layers are just tarballs with files and directories in it. So when the application and framework layer are independent from the OS system layer it should be possible to rearrange them with a new OS layer.</p>
<h2 id="rebasedockerimage">Rebase Docker image</h2>
<p>That is what I have tried to find out. I studied the Docker Hub API and wrote a proof of concept to &quot;rebase&quot; a given Windows Docker image to swap the old Windows OS layers with another one.</p>
<p>The tool works only with information from Docker Hub so it only retrieves metadata and pushes a new manifest back to the Docker Hub. This avoids downloading hundreds of megabytes for the old nanoserver images.</p>
<h3 id="usecases">Use cases</h3>
<ul>
<li>Easily apply Windows Updates to an existing Windows app in seconds. Only the update layer will be swapped.</li>
<li>Provide your app for all available Windows Update layers to avoid download.</li>
<li>Sync multiple images based on different Windows Update layers to the current to avoid downloading several different udpate layers for a multi-container application.</li>
<li>Create images for Server 1709 without having a machine for it.</li>
</ul>
<h3 id="limits">Limits</h3>
<ul>
<li>You cannot move an app from a windowsservercore image to the nanoserver image.</li>
<li>You also cannot move PowerShell scripts into the 1709 nanoserver image as there is no PowerShell installed.</li>
<li>Your framework or application layer may has modified the Windows registry at build time. It then carries the old registry that may not fit to new base layer.</li>
<li>Moving such old application layers on top of new base layers is some kind of time travel. Be warned that this tool may create corrupt images.</li>
</ul>
<p>You can find the <a href="https://github.com/StefanScherer/rebase-docker-image">rebase-docker-image</a> tool on GitHub. It is a Node.js command line tool which is also available on NPM.</p>
<p>The usage looks like this:</p>
<pre><code>$ rebase-docker-image \
    stefanscherer/hello-freiburg:windows \
    -t stefanscherer/hello-freiburg:1709 \
    -b microsoft/nanoserver:1709
</code></pre>
<p>You specify the existing image, eg. &quot;stefanscherer/hello-freiburg:windows&quot; which is based on nanoserver 10.0.14393.x.</p>
<p>With the <code>-t</code> option you specify the target image name that where the final manifest should be pushed.</p>
<p>The <code>-b</code> option specifies the base image you want to use, so most of the time the &quot;microsoft/nanoserver:1709&quot; image.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/11/rebase_docker_image.png" alt="rebase_docker_image"></p>
<p>When we run the tool it does its job in only a few seconds:</p>
<pre><code>Retrieving information about source image stefanscherer/hello-freiburg:windows
Retrieving information about source base image microsoft/nanoserver:10.0.14393.1715
Retrieving information about target base image microsoft/nanoserver:1709
Rebasing image
Pushing target image stefanscherer/hello-freiburg:1709
Done.
</code></pre>
<p>Now on a Windows Server 1709 we can run the application.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/11/hello-freiburg-1709.png-shadow.png" alt="hello-freiburg-1709.png-shadow"></p>
<p>I tried this tool with some other Windows Docker images and was able to rebase the golang:1.9-nanoserver image to have a Golang build environment for 1709 without rebuilding the Golang image by myself.</p>
<p>But I also found situations where the rebase didn't work, so don't expect it to work everywhere.</p>
<h2 id="appveyorcipipeline">AppVeyor CI pipeline</h2>
<p>I also want to show you a small CI pipeline using AppVeyor to build a Windows image with <code>curl.exe</code> installed and provide two variants of that Docker image, one for the old nanoserver and one with the nanoserver:1709 image.</p>
<p>The <a href="https://github.com/StefanScherer/dockerfiles-windows/blob/master/curl/Dockerfile">Dockerfile</a> uses a multi-stage build. In the first stage we download and extract curl and its DLL's. The second stage starts again with the empty nanoserver (the fat one for Windows Server 2016) and then we just COPY deploy the binary into the fresh image. An ENTRYOINT finishes the final image.</p>
<pre><code class="language-Dockerfile">FROM microsoft/nanoserver AS download
ENV CURL_VERSION 7.56.1
WORKDIR /curl
ADD https://skanthak.homepage.t-online.de/download/curl-$CURL_VERSION.cab curl.cab
RUN expand /R curl.cab /F:* .

FROM microsoft/nanoserver
COPY --from=download /curl/AMD64/ /
COPY --from=download /curl/CURL.LIC /
ENTRYPOINT [&quot;curl.exe&quot;]
</code></pre>
<p>This image can be built on AppVeyor and pushed to the Docker Hub.</p>
<p>The <a href="https://github.com/StefanScherer/dockerfiles-windows/blob/master/curl/push.ps1">push.ps1</a> script pushes this image to Docker Hub.</p>
<pre><code>docker push stefanscherer/curl-windows:$version-2016
</code></pre>
<p>Then the rebase tool will be installed and the 1709 variant will be pushed as well to Docker Hub.</p>
<pre><code>npm install -g rebase-docker-image
rebase-docker-image `
  stefanscherer/curl-windows:$version-2016 `
  -t stefanscherer/curl-windows:$version-1709 `
  -b microsoft/nanoserver:1709
</code></pre>
<p>To provide my users the best experience I also draft a manifest list, just like we did for multi-arch images at the <a href="https://stefanscherer.github.io/cross-build-nodejs-with-docker/">Captains Hack day</a>. The final &quot;tag&quot; then contains both Windows OS variants.</p>
<p>On Windows you can use Chocolatey to install the manifest-tool. In the future this feature will be integrated into the Docker CLI as &quot;docker manifest&quot; command.</p>
<pre><code>choco install -y manifest-tool
manifest-tool push from-spec manifest.yml
</code></pre>
<p>The <a href="https://github.com/StefanScherer/dockerfiles-windows/blob/master/curl/manifest.yml">manifest.yml</a> lists both images and joins them together to the final <code>stefanscherer/curl-windows</code> image.</p>
<pre><code class="language-yaml">image: stefanscherer/curl-windows:7.56.1
tags: ['7.56', '7', 'latest']
manifests:
  -
    image: stefanscherer/curl-windows:7.56.1-2016
    platform:
      architecture: amd64
      os: windows
  -
    image: stefanscherer/curl-windows:7.56.1-1709
    platform:
      architecture: amd64
      os: windows
</code></pre>
<p>So on both Windows Server 2016 and Windows Server 1709 the users can run the same image and it will work.</p>
<pre><code>PS C:\Users\demo&gt; docker run stefanscherer/curl-windows
curl: try 'curl --help' or 'curl --manual' for more information
</code></pre>
<p>This requires the next Docker 17.10 EE version to work correctly, but it should be available soon. With older Docker engines it may pick the wrong version of the list of Docker images and fail running it.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This way to &quot;rebase&quot; Docker images works astonishingly good, but keep in mind that this is not a general purpose solution. It is always better to use the correct version on the host to rebuild your Docker images the official way.</p>
<p>Please use the comment below if you have further questions or share what you think about that idea.</p>
<p>Stefan<br>
<a href="https://twitter.com/stefscherer">@stefscherer</a></p>
</div>]]></content:encoded></item><item><title><![CDATA[A closer look at Docker on Windows Server 1709]]></title><description><![CDATA[<div class="kg-card-markdown"><p>Today Microsoft has released Windows Server 1709 in Azure. The ISO file is also available in the MSDN subscription to build local VM's. But spinning up a cloud VM makes it easier for more people.</p>
<p>So let's go to Azure and create a new machine. The interesting VM for me</p></div>]]></description><link>https://stefanscherer.github.io/docker-on-windows-server-1709/</link><guid isPermaLink="false">59f8a705f830c70001a9b8ee</guid><category><![CDATA[Docker]]></category><category><![CDATA[Windows Server 1709]]></category><dc:creator><![CDATA[Stefan Scherer]]></dc:creator><pubDate>Tue, 31 Oct 2017 23:18:14 GMT</pubDate><content:encoded><![CDATA[<div class="kg-card-markdown"><p>Today Microsoft has released Windows Server 1709 in Azure. The ISO file is also available in the MSDN subscription to build local VM's. But spinning up a cloud VM makes it easier for more people.</p>
<p>So let's go to Azure and create a new machine. The interesting VM for me is &quot;Windows Server, version 1709 with Containers&quot; as it comes with Docker preinstalled.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/Bildschirmfoto-2017-10-31-um-22.22.35.png" alt="azure search for 1709"></p>
<p>After a few minutes you can RDP into the machine. But watch out, it is only a Windows Server Core, so there is no full desktop. But for a Docker host this is good enough.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/docker1709-01.png-shadow.png" alt="Docker 17.06.1 EE preinstalled"></p>
<p>As you can see the VM comes with the latest Docker 17.06.1 EE and the new 1709 base images installed.</p>
<h2 id="smaller1709baseimages">Smaller &quot;1709&quot; base images</h2>
<p>On great news is that the base images got smaller. For comparison here are the images of a Windows Server 2016:</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/docker2016-01.png-shadow.png" alt="Windows Server 2016 images"></p>
<p>So with Windows Server 1709 the WindowsServerCore image is only 1/2 the size of the original. And for the NanoServer image is about 1/4 with only 93 MB on the Docker Hub.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/docker-hub-nanoserver.png" alt="docker-hub-nanoserver"></p>
<p>That makes the NanoServer image really attractive to deploy modern microservices with it. As you can see, the &quot;latest&quot; tag is still pointing to the old image. As the 1709 release is a semi-annual release supported for the next 18 months and the current Windows Server 2016 is the LTS version, the latest tags still remain to the older, thicker images.</p>
<p>So when you want to go small, then use the &quot;1709&quot; tags:</p>
<ul>
<li>microsoft/windowsservercore:1709</li>
<li>microsoft/nanoserver:1709</li>
</ul>
<h2 id="whereispowershell">Where is PowerShell?</h2>
<p>The small size of the NanoServer image comes with a cost: There is no PowerShell installed inside the NanoServer image.</p>
<p>So is that really a problem?</p>
<p>Yes and no. Some people have started to write Dockerfiles and installed software using PowerShell in the <code>RUN</code> instructions. This will be a breaking change.</p>
<p>The good news is that there will be a PowerShell Docker image based on the small nanoserver:</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/docker-hub-powershell.png" alt="docker-hub-powershell"></p>
<p>Currently there is PowerShell 6.0.0 Beta 9 available and you can run it with</p>
<pre><code>docker run -it microsoft/powershell:nanoserver
</code></pre>
<p>As you can see PowerShell takes 53 MB on top of the 93 MB nanoserver.</p>
<p>So if you really want to deploy your software with PowerShell, then you might use this base image in your <code>FROM</code> instruction.</p>
<p>But if you deploy a Golang, Node.js, .NET Core application you probably don't need PowerShell.</p>
<p>My experience with Windows Dockerfiles is that the common tasks are</p>
<ul>
<li>downloading a file, zip, tarball from the internet</li>
<li>extracting the archive</li>
<li>Setting an environment variable like PATH</li>
</ul>
<p>These steps could be done with tools like curl (yes, I think of the real one and not the curl alias in PowerShell :-) and some other tools like unzip, tar, ... that are way smaller than the complete PowerShell runtime.</p>
<p>I did a small proof of concept to put some of the tools mentioned into a NanoServer image. You can find the Dockerfile an others in my <a href="https://github.com/StefanScherer/dockerfiles-windows">dockerfiles-windows</a> GitHub repo.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/docker-hub-busybox-windows.png" alt="docker-hub-busybox-windows"></p>
<p>As you can see it only takes about 2 MB to have download and extracting tools. The remaining <code>cmd.exe</code> in the NanoServer image is still good enough to run these tools in the <code>RUN</code> instructions of a Dockerfile.</p>
<h2 id="multistagebuilds">Multi-stage builds</h2>
<p>Another approach to build small images based on NanoServer comes with Docker 17.06. You can use multi-stage builds which brings you so much power and flexibility into a Dockerfile.</p>
<p>You can start with a bigger image, for example the PowerShell image or even the much bigger WindowServerCore image. In that stage of the Dockerfile you have all scripting languages or even build tools or MSI support.</p>
<p>The final stage then uses the smallest NanoServer use <code>COPY</code> deploy instructions for your production image.</p>
<h2 id="caniusemyoldimagesonserver1709">Can I use my old images on Server 1709?</h2>
<p>Well, it depends. Let's test this with a popular application from <a href="http://portainer.io">portainer.io</a>. When we try to run the application on a Windows Server 1709 we get the following error message: <em>The operating system of the container does not match the operating sytem of the host.</em></p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/portainer-on-1709.png-shadow.png" alt="portainer-on-1709.png-shadow"></p>
<p>We can make it work when we run the old container with Hyper-V isolation:</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/portainer-hyperv.png-shadow.png" alt="portainer-hyperv.png-shadow"></p>
<p>For the Hyper-V isolation we need Hyper-V installed. This works in Azure with the v3 machines that allows nested virtualization. If you are using Windows 10 1709 with Hyper-V then you also can run old images in Docker 4 Windows.</p>
<p>But there are many other situations where you are out of luck:</p>
<ul>
<li>other cloud providers that does not have nested virtualization</li>
<li>VirtualBox</li>
</ul>
<p>So my recommendation is to create new Docker images based on 1709 that can be used with Windows 10 1709, or Windows Server 1709 even without Hyper-V. Another advantage is that your users have much smaller downloads and can run your apps much faster.</p>
<h2 id="caniusethe1709imagesonserver2016">Can I use the 1709 images on Server 2016?</h2>
<p><strong>No.</strong> If you try to run one of the 1709 based images on a Windows Server 2016 you see the following error message. Even running it with <code>--isolation=hyperv</code> does not help here as the underlying VM compute of your host does not have all the new features needed.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/nano1709-on-2016.png-shadow.png" alt="nano1709-on-2016.png-shadow"></p>
<h2 id="conclusion">Conclusion</h2>
<p>With Docker on Windows Server 1709 the container images get much smaller. Your downloads are faster and smaller, the containers start faster. If you're interested in Windows Containers then you should switch over to the new server version. The upcoming Linux Containers on Windows feature will run only on Windows 10 1709/Windows Server 1709 and above.</p>
<p>As a software vendor providing Windows Docker images you should provide both variants as people still use Windows 10 and Windows Server 2016 LTS. In a <a href="https://stefanscherer.github.io/poc-build-images-for-1709-without-1709/">following blog post</a> I'll show a way that makes it easy for your users to just run your container image regardless the host operating system they have.</p>
<p>I hope you are as excited as I am about the new features of the new Windows Server 1709. If you have questions feel free to drop a comment below.</p>
<p>Stefan<br>
<a href="https://twitter.com/stefscherer">@stefscherer</a></p>
</div>]]></content:encoded></item><item><title><![CDATA[Cross-build a Node.js app with Docker and deploy to IBM Cloud]]></title><description><![CDATA[<div class="kg-card-markdown"><p>After the DockerCon EU and the Moby Summit in Copenhagen last week we also had an additional Docker Captain's Hack Day. After introducing our current projects to the other Captains we also had time to work together on some ideas.</p>
<blockquote>
<p><em>&quot;Put all Captains available into a room, feed them</em></p></blockquote></div>]]></description><link>https://stefanscherer.github.io/cross-build-nodejs-with-docker/</link><guid isPermaLink="false">59f7701f71f6240001940592</guid><category><![CDATA[Docker]]></category><category><![CDATA[Node.js]]></category><category><![CDATA[multi-arch]]></category><dc:creator><![CDATA[Stefan Scherer]]></dc:creator><pubDate>Mon, 30 Oct 2017 22:37:03 GMT</pubDate><content:encoded><![CDATA[<div class="kg-card-markdown"><p>After the DockerCon EU and the Moby Summit in Copenhagen last week we also had an additional Docker Captain's Hack Day. After introducing our current projects to the other Captains we also had time to work together on some ideas.</p>
<blockquote>
<p><em>&quot;Put all Captains available into a room, feed them well and see what's happening.&quot;</em></p>
</blockquote>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/captains-hack-day.jpg" alt="captains-hack-day"></p>
<h2 id="modernizingswarmvisualizer">Modernizing Swarm Visualizer</h2>
<p>One of the ideas was Swarm Visualizer 2.0. Michael Irwin came up with the idea to rewrite the current Visualizer to be event driven, use a modern React framework and cleanup the code base.</p>
<p>The old one uses a dark theme and shows lots of details for the services with small fonts.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/Bildschirmfoto-2017-10-30-um-19.47.10.png" alt="old swarm visualizer"></p>
<p>Here's a screenshot of an early version of the new UI. With a click on one of the tasks you get more details about that task and its service. All information is updated immediately when you update the service (eg. add or remove labels).</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/Bildschirmfoto-2017-10-30-um-19.50.18.png" alt="new swarm visualizer"></p>
<p>You can try this new Swarm visualizer yourself with the following command:</p>
<pre><code>docker container run \
  --name swarm-viz \
  -p 3000:3000 \
  -v /var/run/docker.sock:/var/run/docker.sock \
  mikesir87/swarm-viz
</code></pre>
<p>I joined Michael's table as I was curious if we can have this visualizer for Windows, too. Especially the new Windows Server 1709 that makes mapping the Docker API into a Windows container as easy as on Linux.</p>
<p>In this blog post I focus on how to build a Node.js app with Docker and don't look into the details of the app itself. I'll show how to improve the Dockerfile to build for multiple platforms and finally how to build a CI pipeline for that. You can find the project on <a href="https://github.com/mikesir87/swarm-viz">github.com/mikesir87/swarm-viz</a>.</p>
<h2 id="initialdockerfile">Initial Dockerfile</h2>
<p>The application is built inside a Docker container. So you even can build it without any developer tools installed, you only need Docker.</p>
<p>Let's have a look at the first version of the Dockerfile for the Linux image. It is a multi-stage build with three stages:</p>
<pre><code class="language-Dockerfile"># Build frontend
FROM node:8.7-alpine as frontend
WORKDIR /app
COPY client/package.json .
RUN npm install
COPY client/ .
RUN npm run build

# Build backend
FROM node:8.7-alpine as backend
WORKDIR /app
COPY api/package.json .
RUN npm install
COPY api/ .
RUN npm run build

# Put them together
FROM node:8.7-alpine
EXPOSE 3000
WORKDIR /app
COPY api/package.json .
RUN npm install --production
COPY --from=backend /app/dist /app/dist
COPY --from=frontend /app/build /app/build
CMD node /app/dist/index.js
</code></pre>
<p>The first stage uses <code>FROM node:8.7-alpine</code> to build the frontend in a container.</p>
<p>The second stage builds the backend in another Alpine container. During that build you also need some development dependencies that aren't needed for the final image.</p>
<p>In the third stage only the dependencies that are relevant at runtime are installed with <code>npm install --production</code>. All artifacts needed from the other stages are also copied into the final image.</p>
<h2 id="makefrommoreflexibleforwindows">Make FROM more flexible for Windows</h2>
<p>I tried to build the app for Windows Server 1709 and had to create a second Dockerfile as I have to use another <code>FROM</code> as node does not have a Windows variant in the official images. And Windows Server 1709 just came out so I had to create a Node.js base image for Windows myself.</p>
<p>So what I did was copying the Dockerfile to Dockerfile.1709 and changed all the</p>
<pre><code>FROM node:8.7-alpine
</code></pre>
<p>lines into</p>
<pre><code>FROM stefanscherer/node-windows:1709
</code></pre>
<p>But now we have duplicated the Dockerfile &quot;code&quot; for only this little difference.</p>
<p>Fortunately you now can use build arguments for the <code>FROM</code> instruction. So with only a little change we can have <strong>ONE</strong> Dockerfile for Linux and Windows.</p>
<pre><code>ARG node=node:8.7-alpine
FROM $node as frontend
</code></pre>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/add-arg.png" alt="add-arg"></p>
<p>On Linux you still can build the image as before without any change.</p>
<p>On Windows I now was able to use this Dockerfile with</p>
<pre><code>docker image build -t viz `
  --build-args node=stefanscherer/node-windows:1709 .
</code></pre>
<p>and use a Windows Node.js base image for all stages. <a href="https://github.com/mikesir87/swarm-viz/pull/2">First pull request</a> done. Check! </p>
<p>And running the manually built image in Windows Server 1709 looks very similar to Linux:</p>
<pre><code>docker container run `
  -p 3000:3000 `
  -u ContainerAdministrator `
  -v //./pipe/docker_engine://./pipe/docker_engine `
  viz
</code></pre>
<h2 id="goingmultiarch">Going multi-arch</h2>
<p>We showed the Windows Swarm visualizer to other Captains and we discussed how to go to more platforms. Phil Estes, a very active member of the Docker community who's helping push the multi-architecture support in Docker forward and the maintainer of the <a href="https://github.com/estesp/manifest-tool">manifest-tool</a>, commented:</p>
<p><em>With Golang it is easy to build multi-arch images, just cross-build a static binary with <code>GOARCH=bar go build app.go</code> and copy the binary in an empty <code>FROM scratch</code> image.</em></p>
<p>Hm, we use Node.js here, so what has to be done instead?</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/captain-hack-day-1.jpg" alt="captain-hack-day-1"></p>
<p>Well, instead of the <code>scratch</code> image we need the <code>node</code> image for the Node.js runtime. So we had to <strong>choose the desired architecture</strong> and then copy all sources and dependencies into that image.</p>
<p>Our Node.js application uses Express, Dockerode and some other dependencies, that are platform independent. So this simple copy approach should do it, we thought.</p>
<p>We added another build stage in the Dockerfile where we switch to the desired platform. You may know, the <code>node</code> image on Docker Hub is already a multi-arch image. But in this case we want to build - let's say on Linux/amd64 - for another platform like the IBM s390 mainframe.</p>
<p>With another build argument to specify the target platform for the final stage we came up with this:</p>
<pre><code class="language-Dockerfile">ARG node=node:8.7-alpine
ARG target=node:8.7-alpine

FROM $node as frontend
...

FROM $target
EXPOSE 3000
COPY --from=proddeps /app /app
CMD node /app/dist/index.js
</code></pre>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/add-target.png" alt="add-target"></p>
<p>As Phil works for IBM he could easily verify our approach. We built an IBM version of the Swarm visualizer with</p>
<pre><code>docker image build -t mikesir87/swarm-viz \
  --build-arg target=s390x/node:8.7 .
</code></pre>
<p>and pushed it to the Docker Hub. Phil then pulled and started the container in IBM Cloud and showed us the visualizer UI. Hurray!</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/deploy-to-ibm.jpg" alt="deploy-to-ibm"></p>
<p>The <a href="https://github.com/mikesir87/swarm-viz/pull/2">second pull request</a> was accepted. Check! </p>
<p>Now we needed some more automation to build and push the Docker images.</p>
<h2 id="addingamultiarchcipipeline">Adding a multi-arch CI pipeline</h2>
<p>I've done that several times for my Raspberry Pi projects, so cherry-picked the relevant parts from other repos. For the CI pipeline we choose Travis CI, but any other CI cloud service could be used that allows multi-stage builds.</p>
<p>The <a href="https://github.com/mikesir87/swarm-viz/blob/master/.travis.yml">.travis.yml</a> uses a matrix build for all architectures. Currently we're building it for only two platforms:</p>
<pre><code class="language-yaml">sudo: required

services:
 - docker

env:
  matrix:
    - ARCH=amd64
    - ARCH=s390x

script:
  - ./travis-build.sh
</code></pre>
<h3 id="build">build</h3>
<p>The <a href="https://github.com/mikesir87/swarm-viz/blob/master/travis-build.sh">travis-build.sh</a> then is called for each architecture of that matrix and we run the corresponding build.</p>
<pre><code>docker image build -t mikesir87/swarm-viz \
    --build-arg target=$ARCH/node:8.7 .
</code></pre>
<h3 id="deploy">deploy</h3>
<p>As a final step in the .travis.yml we push every image to Docker Hub and tag it with the Git commit id. At this early stage of the project this is good enough. Later on you can think of tagged release builds etc.</p>
<p>The <a href="https://github.com/mikesir87/swarm-viz/blob/master/travis-deploy.sh">travis-deploy.sh</a> pushes the Docker image for each architecture to the Docker Hub with a different tag using the <code>$ARCH</code> variable we get from the matrix build.</p>
<pre><code>docker image push &quot;$image:linux-$ARCH-$TRAVIS_COMMIT&quot;
</code></pre>
<p>In the amd64 build we additionally download and use the manifest-tool to push a manifest list with the final tag.</p>
<pre><code>manifest-tool push from-args \
    --platforms linux/amd64,linux/s390x \
    --template &quot;$image:OS-ARCH-$TRAVIS_COMMIT&quot; \
    --target &quot;$image:latest&quot;
</code></pre>
<p>You can verify that the <code>latest</code> tag is already a manifest list with another Docker image provided by Phil</p>
<pre><code>$ docker container run --rm mplatform/mquery mikesir87/swarm-viz
Image: mikesir87/swarm-viz:latest
 * Manifest List: Yes
 * Supported platforms:
   - amd64/linux
   - s390x/linux
</code></pre>
<h2 id="futureimprovements">Future improvements</h2>
<p>In the near future we will also add a Windows build using AppVeyor CI to provide Windows images and also put them into the manifest list. This step would also be needed for Golang projects as you cannot use the empty <code>scratch</code> image on Windows.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/ci-pipeline-1.png" alt="ci-pipeline-1"></p>
<p>If you watch closely we have used <code>node:8.7</code> for the final stage. There is no multi-arch <code>alpine</code> image, so there also is no <code>node:8.7-alpine</code> as multi-arch image. But the maintainers of the official Docker images are working hard to add this missing piece to have small images for all architectures.</p>
<pre><code>$ docker container run --rm mplatform/mquery node:8.7-alpine
Image: node:8.7-alpine
 * Manifest List: Yes
 * Supported platforms:
   - amd64/linux
</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>At the end of the Hack day we were really excited how far we came in only a few hours and learned that cross-building Node.js apps with Docker and deploying them as multi-arch Docker images isn't that hard.</p>
<p>Best of all, the users of your Docker images don't have to think about these details. They just can run your image on any platform. Just use the command I showed at the beginning as this already uses the multi-arch variant of the next Swarm visualizer app.</p>
<blockquote>
<p>So give multi-arch a try in your next Node.js project to run your app on any platform!</p>
</blockquote>
<p>If you want to learn more about multi-arch (and you want to see Phil with a bow tie) then I can recommend the <a href="https://dockercon.docker.com/watch/Q2LpoYRL3drmxzWc8yDmn9">Docker Multi-arch All the Things</a> talk from DockerCon EU with Phil Estes and Michael Friis.</p>
<p>In my lastest <a href="https://www.slideshare.net/stefscherer/bauen-und-verteilen-von-multiarch-docker-images-fr-linux-und-windows">multi-arch slidedeck</a> there are also more details about the upcoming <code>docker manifest</code> command that will replace the manifest-tool in the future.</p>
<p>Thanks <a href="https://twitter.com/mikesir87">Michael</a> for coming up with that idea, thanks <a href="https://twitter.com/estesp">Phil</a> for the manifest-tool and testing the visualizer. Thanks <a href="https://twitter.com/quintus23m">Dieter</a> and <a href="https://twitter.com/bretfisher">Bret</a> for the photos. You can follow us on Twitter to see what these Captains are doing next.</p>
<p>Stefan<br>
<a href="https://twitter.com/stefscherer">@stefscherer</a></p>
</div>]]></content:encoded></item><item><title><![CDATA[DockerCon: LCOW and Windows Server 1709]]></title><description><![CDATA[<div class="kg-card-markdown"><p>Last week was a busy week as a Docker Captain. Many of us came to Copenhagen to DockerCon EU 2017. You may have heard of the surprising news about Kubernetes coming to Docker. But there were also some other new announcements about Windows Containers.</p>
<h2 id="dockeronwindowsworkshop">Docker on Windows Workshop</h2>
<p>On Monday</p></div>]]></description><link>https://stefanscherer.github.io/dockercon-lcow-and-windows-server-1709/</link><guid isPermaLink="false">59f3b65cdd4c1b0001e301e7</guid><category><![CDATA[DockerCon]]></category><category><![CDATA[windows-containers]]></category><category><![CDATA[LCOW]]></category><category><![CDATA[Windows Server 1709]]></category><dc:creator><![CDATA[Stefan Scherer]]></dc:creator><pubDate>Sat, 28 Oct 2017 00:18:11 GMT</pubDate><content:encoded><![CDATA[<div class="kg-card-markdown"><p>Last week was a busy week as a Docker Captain. Many of us came to Copenhagen to DockerCon EU 2017. You may have heard of the surprising news about Kubernetes coming to Docker. But there were also some other new announcements about Windows Containers.</p>
<h2 id="dockeronwindowsworkshop">Docker on Windows Workshop</h2>
<p>On Monday I helped <a href="https://twitter.com/EltonStoneman">Elton Stoneman</a> in his Docker on Windows Workshop. This time it was a full-day workshop and it was fully packed with 50 people.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/dowws.jpg" alt="Docker on Windows Workshop"></p>
<p>Elton is always running the workshop at a rapic pace, but don't worry the workshop material is all public <a href="https://github.com/sixeyed/docker-windows-workshop">available on GitHub</a>. So we went through dockerizing <a href="http://ASP.NET">ASP.NET</a> apps, adding Prometheus, Grafana and an ELK stack for monitoring, building a Jenkins CI pipeline and finally running a Docker Swarm. There is lots of things to look up in the material. If you prefer a book, I can recommend his <a href="https://www.amazon.de/Docker-Windows-Elt%E2%80%A6">Docker on Windows</a> book which is also fully packed with many tips and tricks.</p>
<h2 id="lcowtheinsidestory">LCOW - The Inside Story</h2>
<p>One of my favorite talks was by <a href="https://twitter.com/gigastarks">John Starks</a> from Microsoft about Linux Container on Windows - The Inside Story. He explained how LinuxKit is used to run a small HyperV VM for the Linux containers to provide the Linux kernel. On his Windows 10 1709 machine he also gave pretty good live demos. The <a href="https://dockercon.docker.com/watch/U7Bxp66uKmemZssjCTyXkm">video is online</a> and is worth watching.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/dcon-lcow.jpg" alt="Linux and Windows containers side-by-side"></p>
<p>In the photo you can see an alpine and nanoserver container running side-by-side. So you will no longer need to switch between Linux and Windows containers, it just works. He also showed that volumes work between Linux and Windows containers. This demo was done with a special Docker engine as not all pull requests haven't been merged. But still challenging for me to try this on a own machine ...</p>
<h2 id="windowsserver1709">Windows Server 1709</h2>
<p>During the DockerCon week Microsoft has announced the availability of Windows Server Version 1709 for download. I first looked at the Azure Portal, but found nothing yet. I also couldn't find the downloads.</p>
<p>So after the LCOW talk I used a Windows 10 VM in Azure and installed the Fall Creators Update to have 1709 on that desktop machine. I found the missing pull request and compiled a Docker engine from source and then I had my LCOW moment:</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/docker-run-lcow.gif" alt="docker-run-lcow"></p>
<p>When you see this the first time working and know what technical details had to be solved make make it look so simple and easy - awesome!</p>
<p>The next day I found the Windows Server 1709 ISO in my MSDN subscription. So I could start working on a Packer template in my <a href="https://github.com/StefanScherer/packer-windows">packer-windows</a> GitHub repo to automate the creation of such Windows VM's. But DockerCon is to meet people and learn new things: <a href="https://twitter.com/NicholasDille">Nicholas Dille</a> went another very interesting way to <a href="http://dille.name/blog/2017/10/25/building-a-windowscontainer-docker-host-without-running-windows-setup/">build a VM with Docker without running Windows Setup</a>.</p>
<h2 id="smallerwindowsimages">Smaller Windows images</h2>
<p>In the last months we could follow the progress of the Windows Server in several Insider builds. I blogged about the <a href="https://stefanscherer.github.io/exploring-new-nanoserver-insider-images/">smaller NanoServer Insider images</a> in July going down to 80-90 MByte. Now with the new release of Windows Server 1709 and Windows 10 version 1709 we now can use official images.</p>
<ul>
<li>microsoft/windowsservercore:1709</li>
<li>microsoft/nanoserver:1709</li>
<li>microsoft/dotnet:2.0.0-*-nanoserver-1709</li>
<li>microsoft/aspnet:4.7.1-windowsservercore-1709</li>
</ul>
<p>The biggest discussion is about having no PowerShell in the small nanoserver image. For me it's a nice fit to just <code>COPY</code> deploy microservices into the Windows image.</p>
<p>I haven't seen an official PowerShell base image based on nanoserver, but there is at least the beta version</p>
<ul>
<li>microsoft/powershell:6.0.0-beta.9-nanoserver-1709</li>
</ul>
<p>I also have pushed some images to the Docker Hub to get started with other languages and tools.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/Bildschirmfoto-2017-10-19-um-11.14.43.png" alt="Bildschirmfoto-2017-10-19-um-11.14.43"></p>
<p>If you don't have HyperV installed in Windows Server 1709 (maybe you are running a VM in the Cloud) then you cannot run older Windows Docker image on the new server. All images have to be built based on the new 1709 base images.</p>
<p>Windows 10 users always use HyperV to run Linux or Windows containers, so you don't feel that hard constraint on your developer machine.</p>
<p>It will be interesting to see how the multiple Windows versions evolve and when the next Insider program is giving us early access to the upcoming features.</p>
<h2 id="captainshackday">Captains Hack Day</h2>
<p>On our Docker Captains Hack Day <a href="https://twitter.com/mikesir87">Michael Irwin</a> has started a better <a href="https://github.com/mikesir87/swarm-viz">Swarm Visualizer 2.0</a>. During the day we have added a first CI pipeline and - of course - Windows support. But not only Windows! With some magic multi-stage multi-arch builds we also managed to cross-build the visualizer on an Intel machine and create a Docker image for IBM z390 mainframes. <a href="https://twitter.com/estesp">Phil Estes</a> tested the image in the IBM cloud. I'll write a more detailed blog post about how to cross-build Node.js apps with Docker.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/10/captain-hack-day.jpg" alt="captain-hack-day"></p>
<p>That was a fascinating week at DockerCon. Thanks to Jenny, Ashlinn, Victor, Mano ... for making this event so wonderful. I had a lot of hallway tracks to talk with many people about Windows Containers in devolpment and production. Share and learn!</p>
<p>Stefan<br>
<a href="https://twitter.com/stefscherer">@stefscherer</a></p>
</div>]]></content:encoded></item><item><title><![CDATA[Use Docker to Search in 320 Million Pwned Passwords]]></title><description><![CDATA[<div class="kg-card-markdown"><p>This week Troy Hunt, a security researcher announced a freely downloadable list of pwned passwords. Troy is the creator of <a href="https://haveibeenpwned.com">Have I Been Pwned?</a> website and service that will notify you when one of your registered email addresses have been compromised by a data breach.</p>
<p>In his latest blog post</p></div>]]></description><link>https://stefanscherer.github.io/use-docker-to-search-in-320-million-pwned-passwords/</link><guid isPermaLink="false">5986d4ec688a490001540976</guid><category><![CDATA[Docker]]></category><category><![CDATA[multi-stage]]></category><category><![CDATA[HaveIBeenPwned]]></category><category><![CDATA[passwords]]></category><category><![CDATA[Security]]></category><dc:creator><![CDATA[Stefan Scherer]]></dc:creator><pubDate>Sat, 05 Aug 2017 00:55:07 GMT</pubDate><content:encoded><![CDATA[<div class="kg-card-markdown"><p>This week Troy Hunt, a security researcher announced a freely downloadable list of pwned passwords. Troy is the creator of <a href="https://haveibeenpwned.com">Have I Been Pwned?</a> website and service that will notify you when one of your registered email addresses have been compromised by a data breach.</p>
<p>In his latest blog post he introduced <a href="https://www.troyhunt.com/introducing-306-million-freely-downloadable-pwned-passwords/">306 Million Freely Downloadable Pwned Passwords</a> with an update of another 14 Million just on the following day. He also has setup a online search at <a href="https://haveibeenpwned.com/Passwords">https://haveibeenpwned.com/Passwords</a></p>
<p>You can enter passwords and check if they have been compromised. <strong>But do not enter actively used passwords here</strong>, even if Troy is a nice person living in sunny Australia.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/08/pwned-passwords.png" alt="Pwned Passwords online service"></p>
<p>My recommendation is</p>
<ol>
<li>If you are in doubt if your password has been pwned, just <strong>change it first</strong> and then check the old one in the online form.</li>
<li>Use a <strong>Password manager</strong> like 1Password to create an individual long random password <strong>for each service</strong> you use.</li>
</ol>
<p>But the huge password list is still quite interesting to work with.</p>
<h2 id="letsbuildalocalsearch">Let's build a local search</h2>
<p>What you can do is download the list of passwords (about 5 GByte compressed) and search locally in a safe place. You won't get the cleartext passwords, but only SHA1 sums of them. But we can create SHA1 sums of the passwords we want to search in this huge list.</p>
<p>You can download the files that are compressed with 7-Zip. You also need a tool to create a SHA1 sum of a plain text. And then you need another tool, a database or algorithm to quickly search in that text file that has nearly 320 Million lines.</p>
<h2 id="usedockerforthetask">Use Docker for the task</h2>
<p>I immediately thought of a Container that has all these tools installed. But I didn't want to add the huge password lists into that container as it would build a Docker image of about 12 GByte or probably 5-6 GB Docker image on the Docker Hub.</p>
<p>The password files should be persisted locally on your laptop and mounted into the container to search in them with the tools needed for the task.</p>
<p>And I want to use some simple tools to get the work done. A first idea was born in the comments of Troys blog post where someone showed a small bash script with <code>grep</code> to search in the file.</p>
<p>I first tried <code>grep</code>, but this took about 2 minutes to find the hash in the file. So I searched a little bit and found <a href="http://sgrep.sourceforge.net"><code>sgrep</code></a> - a tool to grep in sorted files. Luckily the password files are sorted by the SHA1 hash. But I found only the source code and there is no standard package to install it. So we also need a C compiler for that.</p>
<p>In times before Docker you had a lot of stress installing many tools on your computer. But let's see how Docker can help us with all these steps.</p>
<h2 id="buildthedockerimage">Build the Docker image</h2>
<p>I found the Sources of sgrep on <a href="https://github.com/colinscape/sgrep">GitHub</a> and we will need Make and a C compiler to build the <code>sgrep</code> binary.</p>
<p>I will use a <strong>multi-stage build</strong> Dockerfile and explain every single line. You can build the image line by line and see the benefits of build caches while working on the <code>Dockerfile</code>. So after adding a line to the file you can run <code>docker build -t pwned-passwords .</code> to build and update the image.</p>
<p>For the beginning let's choose a small Linux base image. We will name the first stage as <code>build</code>. So the <code>Dockerfile</code> starts with</p>
<pre><code>FROM alpine:3.6 AS build
</code></pre>
<p>The next step is we have to install Git, Make and the C compiler with its header files.</p>
<pre><code>RUN apk update &amp;&amp; apk add git make gcc musl-dev
</code></pre>
<p>Now we clone the GitHub repo with the source code of sgrep.</p>
<pre><code>RUN git clone https://github.com/colinscape/sgrep
</code></pre>
<p>In the next line I'll create a bin folder that is needed for the build process. Then we go to the source directory and run the <code>make</code> command as there is a <code>Makefile</code> in that directory.</p>
<pre><code>RUN mkdir sgrep/bin &amp;&amp; cd sgrep/src &amp;&amp; make
</code></pre>
<p>After these steps we have the <code>sgrep</code> binary compiled for Alpine Linux. But we also have installed a ton of other tools.</p>
<p>Now put all these instructions into a <code>Dockerfile</code> and build the Docker image.</p>
<pre><code>$ docker build -t pwned-passwords .
</code></pre>
<p>Let's inspect all image layers we have created so far.</p>
<pre><code>$ docker history --format &quot;{{.ID}}\t{{.Size}}\t{{.CreatedBy}}&quot; pwned-passwords
78171a118279	24.5kB	/bin/sh -c mkdir sgrep/bin &amp;&amp; cd sgrep/src...
2323bcb14b5f	93.6kB	/bin/sh -c git clone https://github.com/co...
8ec1470030af	119MB	/bin/sh -c apk update &amp;&amp; apk add git make ...
7328f6f8b418	0B	/bin/sh -c #(nop)  CMD [&quot;/bin/sh&quot;]
&lt;missing&gt;	3.97MB	/bin/sh -c #(nop) ADD file:4583e12bf5caec4...
</code></pre>
<p>As you can see we now have a Docker image of more than 120 MByte, but the <code>sgrep</code> binary is only 15 KByte. Yes, this is no typo. Yes, we will grep through GByte of data with a tiny 15 KByte binary.</p>
<h2 id="multistagebuildforthewin">Multi-stage build for the win</h2>
<p>With Docker 17.05 and newer you can now add another <code>FROM</code> instruction and start with a new stage in your <code>Dockerfile</code>. The last stage will create the final Docker image. So every instruction after the last <code>FROM</code> defines what goes into the image you want to share eg. on Docker Hub.</p>
<p>So let's start our final stage of our Docker image build with</p>
<pre><code>FROM alpine:3.6
</code></pre>
<p>The last stage does not need a name. Now we have an empty Alpine Linux again, all the 120 MByte of development environment won't make it into the final image. But if you build the Docker image more than once the temporary layers are still there and will be reused if they are unmodified. So the Docker build cache helps you speed up while working on the shell script.</p>
<p>In the previous build stage we have created the much faster <code>sgrep</code> command. What we now need is a small shell script that converts a plaintext password into a SHA1 sum and runs the <code>sgrep</code> command.</p>
<p>To create a SHA1 sum I'll use <code>openssl</code> command. And it would be nice if the shell script can download the huge files for us. As the files are compressed with 7-zip we also need <code>wget</code> to download and <code>7z</code> to extract them.</p>
<p>In the next instruction we install OpenSSL and the 7-Zip tool.</p>
<pre><code>RUN apk update &amp;&amp; apk add openssl p7zip
</code></pre>
<p>The <code>COPY</code> instruction has an option <code>--from</code> where you can specify another named stage of your build. So we copy the compiled <code>sgrep</code> binary from the <code>build</code> stage into the local bin directory.</p>
<pre><code>COPY --from=build /sgrep/bin/sgrep /usr/local/bin/sgrep
</code></pre>
<p>The complete shell script is called <code>search</code> and can be found in <a href="https://github.com/StefanScherer/pwned-passwords">my pwned-passwords</a> GitHub repo. Just assume we have it in the current directory. The next <code>COPY</code> instruction copies it from your real machine into the image layer.</p>
<pre><code>COPY search /usr/local/bin/search
</code></pre>
<p>As the last line of the <code>Dockerfile</code> we define an entrypoint to run this shell script if we run the Docker container.</p>
<pre><code>ENTRYPOINT [&quot;/usr/local/bin/search&quot;]
</code></pre>
<p>Now append these lines to the <code>Dockerfile</code> and build the complete image. You will see that the first layers are already cached and only the last stage will be built.</p>
<h3 id="thesearchscript">The search script</h3>
<p>You can find the <a href="https://github.com/StefanScherer/pwned-passwords/blob/master/search"><code>search</code> script</a> in my GitHub repo as well as the <code>Dockerfile</code>. You only need these two tiny files to build the Docker image yourself.</p>
<pre><code>#!/bin/sh
set -e

if [ ! -d /data ]; then
  echo &quot;Please run this container with a volume mounted at /data.&quot;
  echo &quot;docker run --rm -v \ $(pwd):/data pwned-passwords $*&quot;
  exit 1
fi

FILES=&quot;pwned-passwords-1.0.txt pwned-passwords-update-1.txt&quot;
for i in $FILES
do
  if [ ! -f &quot;/data/$i&quot; ]; then
    echo &quot;Downloading $i&quot;
    wget -O &quot;/tmp/$i.7z&quot; &quot;https://downloads.pwnedpasswords.com/passwords/$i.7z&quot;
    echo &quot;Extracting $i to /data&quot;
    7z x -o/data &quot;/tmp/$i.7z&quot;
    rm &quot;/tmp/$i.7z&quot;
  fi
done

if [[ $1 != &quot;&quot; ]]
then
PWD=$1
else
PWD=&quot;password&quot;
echo &quot;checking $PWD&quot;
fi

hash=`echo -n $PWD | openssl sha1 | awk '{print $2}' | awk 'BEGIN { getline; print toupper($0)  }'`
echo &quot;Hash is $hash&quot;
totalcount=0
for i in $(sgrep -c $hash /data/*.txt)
do
  file=$(echo &quot;$i&quot; | cut -f1 -d:)
  count=$(echo &quot;$i&quot; | cut -f2 -d:)
  if [[ $count -ne 0 ]]; then
    echo &quot;Oh no - pwned! Found $count occurences in $file&quot;
  fi
  totalcount=$(( $totalcount + $count ))
done
if [[ $totalcount -eq 0 ]]; then
  echo &quot;Good news - no pwnage found!&quot;
else
  exit 1
fi
</code></pre>
<h2 id="buildthefinalimage">Build the final image</h2>
<p>Now with these two files, <code>Dockerfile</code> and <code>search</code> shell script build the small Docker image.</p>
<pre><code>$ docker build -t pwned-passwords .
</code></pre>
<p>Let's have a look at the final image layers with</p>
<pre><code>$ docker history --format &quot;{{.ID}}\t{{.Size}}\t{{.CreatedBy}}&quot; stefanscherer/pwned-passwords
24eca60756c8	0B	/bin/sh -c #(nop)  ENTRYPOINT [&quot;/usr/local...
c1a9fc5fdb78	1.04kB	/bin/sh -c #(nop) COPY file:ea5f7cefd82369...
a1f4a26a50a4	15.7kB	/bin/sh -c #(nop) COPY file:bf96562251dbd1...
f99b3a9601ea	10.7MB	/bin/sh -c apk update &amp;&amp; apk add openssl p...
7328f6f8b418	0B	/bin/sh -c #(nop)  CMD [&quot;/bin/sh&quot;]
&lt;missing&gt;	3.97MB	/bin/sh -c #(nop) ADD file:4583e12bf5caec4...
</code></pre>
<p>As you can see, OpenSSL and 7-Zip take about 10 MByte, the 16 KByte sgrep binary and the 1 KByte shell script are sitting on top of the 4 MByte Alpine base image.</p>
<p>I also have pushed this image to the <a href="https://hub.docker.com/r/stefanscherer/pwned-passwords/">Docker Hub</a> with a compressed size of about 7 MByte. If you trust me, you can use this Docker image as well. But you will learn more how multi-stage builds feel like if you build the image yourself.</p>
<h2 id="searchforpwnedpasswords">Search for pwned passwords</h2>
<p>We now have a small 14.7 MByte Linux Docker image to search for pwned passwords.</p>
<p>Run the container with a folder mounted to <code>/data</code>. If you forgot this, the script will show you how to run it.</p>
<p>Running the container for the first time it will download the two password files (5 GByte) which may take some minutes depending on your internet connectivity.</p>
<p>After the script has downloaded everything two files should appear in the current folder. For me it looks like this:</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/08/list.png" alt="file list"></p>
<p>Now search for passwords by adding a plaintext password as an argument</p>
<pre><code>$ docker run --rm -v $(pwd):/data pwned-passwords troyhunt
Hash is 0CCE6A0DD219810B5964369F90A94BB52B056494
Oh no - pwned! Found 1 occurences in /data/pwned-passwords-1.0.txt
</code></pre>
<p>If you don't trust my script or the <code>sgrep</code> command, the run the container without network connectivity</p>
<pre><code>$ docker run --rm -v $(pwd):/data --network none pwned-passwords secret4949
Hash is 6D26C5C10FF089BFE81AB22152E2C0F31C58E132
Good news - no pwnage found!
</code></pre>
<p>So you have luck, you can securely check that your password <code>secure4949</code> hasn't been breached. But beware this is still no good password :-)</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/08/mac.png" alt="Run pwned-passwords"></p>
<h2 id="worksonwindows">Works on Windows</h2>
<p>If you have Docker installed on your Windows machine, you can also use my Docker image or build the image yourself.</p>
<p>With Docker 4 Windows it only depends on the shell you use.</p>
<p>For PowerShell the command to run the image is</p>
<pre><code>docker run --rm -v &quot;$(pwd):/data&quot; pwned-passwords yourpass
</code></pre>
<p><img src="https://stefanscherer.github.io/content/images/2017/08/ps1.png" alt="PowerShell"></p>
<p>And if you prefer the classic CMD shell use this command</p>
<pre><code>docker run --rm -v &quot;%cd%:/data&quot; pwned-passwords yourpass
</code></pre>
<p><img src="https://stefanscherer.github.io/content/images/2017/08/cmd.png" alt="CMD shell"></p>
<p>On my Windows 7 machine I have to use Docker Machine, but even here you can easily search for pwned passwords. All you have to do is mount a directory for the password files as <code>/data</code> into the container.</p>
<pre><code>docker run --rm -v &quot;/c/Users/stefan.scherer/pwned:/data&quot; stefanscherer/pwned-passwords troyhunt
</code></pre>
<p><img src="https://stefanscherer.github.io/content/images/2017/08/win7.png" alt="Windows 7 with pwned-passwords image"></p>
<h2 id="conclusion">Conclusion</h2>
<p>You now know that there are Millions of passwords out there that may be used in a brute force attack to other online services.</p>
<p>So please use a password manager instead of predictable patterns how to modify passwords for different services.</p>
<p>You also have learned how Docker can keep your computer clean but still compile some open source projects from source code.</p>
<p>You have seen the benefits of multi-stage builds to create and share minimal Docker images without the development environment.</p>
<p>And you now have the possibility to search your current passwords in a save place without leaking it to the internet. Some other online service may collect all the data entered into a form. So keep your passwords secret and change</p>
<p>If you want to hear more about Docker, follow me on Twitter <a href="https://twitter.com/stefscherer">@stefscherer</a>.</p>
</div>]]></content:encoded></item><item><title><![CDATA[Exploring new NanoServer Insider images]]></title><description><![CDATA[<div class="kg-card-markdown"><p>Last week the first Insider preview container images appeared on the Docker Hub. They promise us much smaller sizes to have more lightweight Windows images for our applications.</p>
<p>To use these Insider container images you also need an Insider preview of Windows Server 2016 or Windows 10. Yes, this is</p></div>]]></description><link>https://stefanscherer.github.io/exploring-new-nanoserver-insider-images/</link><guid isPermaLink="false">5986d4ec688a490001540975</guid><category><![CDATA[Docker]]></category><category><![CDATA[Windows]]></category><category><![CDATA[Nano Server]]></category><category><![CDATA[Node.js]]></category><category><![CDATA[Vagrant]]></category><category><![CDATA[Packer]]></category><category><![CDATA[Docker Hub]]></category><category><![CDATA[Insider]]></category><dc:creator><![CDATA[Stefan Scherer]]></dc:creator><pubDate>Tue, 18 Jul 2017 09:42:41 GMT</pubDate><content:encoded><![CDATA[<div class="kg-card-markdown"><p>Last week the first Insider preview container images appeared on the Docker Hub. They promise us much smaller sizes to have more lightweight Windows images for our applications.</p>
<p>To use these Insider container images you also need an Insider preview of Windows Server 2016 or Windows 10. Yes, this is another great announcement that you can get early access and give feedback to the upcoming version of Windows Server. So let's grab it.</p>
<h2 id="windowsserverinsider">Windows Server Insider</h2>
<ol>
<li>
<p>Register at Windows Insider program <a href="https://insider.windows.com">https://insider.windows.com</a> and join the Windows Server Insider program.</p>
</li>
<li>
<p>Download the Windows Server Insider preview ISO from <a href="https://www.microsoft.com/en-us/software-download/windowsinsiderpreviewserver">https://www.microsoft.com/en-us/software-download/windowsinsiderpreviewserver</a></p>
</li>
</ol>
<p>Now you can create a VM and install Docker. You can either build the VM manually and follow the docs <a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/quick-start/using-insider-container-images">&quot;Using Insider Container Images&quot;</a> how to install Docker and pull the Insider container images. Or you can use my Packer template and Vagrant environment to automate these steps. The walkthrough is described at</p>
<p><a href="https://github.com/StefanScherer/insider-docker-machine">https://github.com/StefanScherer/insider-docker-machine</a></p>
<h2 id="windowsinsiderimages">Windows Insider images</h2>
<p>There are four new Docker images available with a much smaller footprint.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/07/windows_insider_images.png" alt="Windows Insider images"></p>
<ul>
<li>microsoft/windowsservercore-insider</li>
<li>microsoft/nanoserver-insider</li>
<li>microsoft/nanoserver-insider-dotnet</li>
<li>microsoft/nanoserver-insider-powershell</li>
</ul>
<p>The Windows Server Core Insider image got down from 5 GB to only 2 GB which saves a lot of bandwidth and download time.</p>
<p>You may wonder why there are three Nano Server Insider images and why there is one without PowerShell.</p>
<h2 id="aimingthesmallestwindowsbaseimage">Aiming the smallest Windows base image</h2>
<p>If we compare the image sizes of the current <code>microsoft/nanoserver</code> image with its base layer and update layer with the new Insider images you can see the reason.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/07/nanoserver_sizes.png" alt="NanoServer sizes"></p>
<p>If you want to ship your application in a container image you don't want to ship a whole operating system, but only the parts needed to run the application.</p>
<p>And to ship faster is to ship smaller images. For many applications you do not need eg. PowerShell inside your base image at runtime which would take another 54 MByte to download from the Docker registry.</p>
<p>Let's have a look at current Windows Docker images available on the Docker Hub. To run a Golang webserver for example on an empty Windows Docker host you have to pull the 2MB binary and the two NanoServer base layers with hundreds of MB to run it in a container.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/07/docker-pull-whoami.png" alt="docker pull whoami"></p>
<p>Of course these base images have to be downloaded only once as other NanoServer container images will use the same base image. But if you work with Windows containers for a longer time you may have noticed that you still have to download different update layers from time to time that pull another 122 MB.</p>
<p>And if the NanoServer base image is much smaller then the updates also will be smaller and faster to download.</p>
<p>With the new Insider container images you can build and run containerized .NET core applications that are still smaller than the NanoServer + PowerShell base image.</p>
<h2 id="nodejs">Node.js</h2>
<p>Another example is providing a Node.js container image based on the new NanoServer Insider image with only 92 MByte. We have just cut off &quot;3&quot; hundred MB.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/07/nodejs_nanoserver_sizes-3.png" alt="Node.js NanoServer sizes"></p>
<p>If we compare that with some of the Linux Node.js container images we are at about the size of the the slim images.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/07/Bildschirmfoto-2017-07-14-um-08.53.24.png" alt="Node.js slim image sizes"></p>
<h2 id="multistagebuild">Multi-stage build</h2>
<p>To build such small Windows images comes with a cost. You have to live without PowerShell. But the new multi-stage build introduced with Docker 17.05 really helps you and you can use PowerShell before the final image layers are built.</p>
<p>If you haven't heard about multi-stage builds its concept is to have multiple <code>FROM</code> instructions in a <code>Dockerfile</code>. Only the last <code>FROM</code> until the end of the file will build the final container image. This is also called the last stage. In all the other stages you don't have to optimze too much and can use the build cache much better. You can read more about <a href="https://blog.docker.com/2017/07/multi-stage-builds/">multi-stage builds</a> at the Docker Blog.</p>
<p>Let's have a closer look how to build a small Node.js base image. You can find the complete <a href="https://github.com/StefanScherer/dockerfiles-windows/blob/07cedcf2cc93e669bba9c961121feda6f43dab59/node/8.1/nano/Dockerfile">Dockerfile</a> on GitHub.</p>
<p>In the first stage I'm lazy and even use the <code>microsoft/windowsservercore-insider</code> image. The reason is that I'm using the GPG tools to verify the downloads and these tools don't run quiet well in NanoServer at the moment.</p>
<pre><code class="language-Dockerfile"># escape=`
FROM microsoft/windowsservercore-insider as download
SHELL [&quot;powershell&quot;, &quot;-Command&quot;, &quot;$ErrorActionPreference = 'Stop'; $ProgressPreference = 'SilentlyContinue';&quot;]
RUN Invoke-WebRequest ... 
RUN Expand-Archive ...
</code></pre>
<p>The <code>Dockerfile</code> has a second <code>FROM</code> instruction which then uses the smallest Windows base image. In that stage you normally <code>COPY</code> deploy files and folders from previous stages. In our case we copy the Node.js installation folder into the final image.</p>
<p>The one <code>RUN</code> instruction sets the <code>PATH</code> environment variable with the <code>setx</code> command instead of PowerShell commands.</p>
<pre><code class="language-Dockerfile">FROM microsoft/nanoserver-insider
ENV NPM_CONFIG_LOGLEVEL info
COPY --from=download /nodejs /nodejs
RUN setx PATH &quot;%PATH%;C:\nodejs;%APPDATA%\npm&quot;
CMD [ &quot;node.exe&quot; ]
</code></pre>
<p>Users of such a Node.js base image can work as usual by <code>COPY</code> deploy their source tree and node_modules folder into that image and run the application as a small container.</p>
<pre><code class="language-Dockerfile">FROM stefanscherer/node-windows:8.1.4-insider
WORKDIR /code
COPY . /code
CMD [&quot;node.exe&quot;, &quot;app.js&quot;]
</code></pre>
<p>So all you have to do is change the <code>FROM</code> instruction to the smaller insider Node.js image.</p>
<h2 id="furtherinsiderimages">Further Insider images</h2>
<p>I have pushed some of my first Insider images to the Docker Hub so it may be easier for you to try out different languages.</p>
<ul>
<li>stefanscherer/node-windows:6.11.1-insider</li>
<li>stefanscherer/node-windows:8.1.4-insider</li>
<li>stefanscherer/golang-windows:1.8.3-insider</li>
<li>stefanscherer/dockertls-windows:insider</li>
</ul>
<p>If you want to see how these images are built, then you can find the <code>Dockerfiles</code> in the latest pull requests of my <a href="https://github.com/StefanScherer/dockerfiles-windows">https://github.com/StefanScherer/dockerfiles-windows</a> repo.</p>
<h2 id="dockervolumes">Docker Volumes</h2>
<p>If you have worked with Docker Volumes on Windows you may know this already. Node.js and other tools and languages have problems when they want to get the real name of a file or folder that is mapping from the Docker host into the container.</p>
<p>Node.js for example thinks the file is in the folder <code>C:\ContainerMappedDirectories</code>, but cannot find the file there. There is a workaround described in Elton Stoneman's blog post <a href="https://blog.sixeyed.com/docker-volumes-on-windows-the-case-of-the-g-drive/">&quot;Introducing the 'G' Drive&quot;</a> to map it to another drive letter.</p>
<p>With the new Insider preview I see a great improvement on that topic. Running normal Windows containers without the HyperV isolation there is no longer a symbolic link.</p>
<p>If we run the Node.js container interactively and map the folder <code>C:\code</code> into the container we can list the <code>C:</code>drive and see that the <code>code</code> folder is a normal directory.</p>
<pre><code>docker run -v C:\code:C:\code stefanscherer/node-windows:8.1.4-insider cmd /c dir
</code></pre>
<p><img src="https://stefanscherer.github.io/content/images/2017/07/docker-run-nodejs.png-shadow.png" alt="docker run volume"></p>
<p>With this setup you are able to mount your source code into the Node.js container and run it eg. with <code>nodemon</code> to live reload it after changing it on the host.</p>
<p>Unfortunately this is not available with the Hyper-V isolation that is the default on Windows 10 Insider machines.</p>
<p>Running the same command with <code>--isolation=hyperv</code> shows the symlinked directory which Node.js cannot handle at the moment.</p>
<pre><code>docker run -v C:\code:C:\code --isolation=hyperv stefanscherer/node-windows:8.1.4-insider cmd /c dir
</code></pre>
<p><img src="https://stefanscherer.github.io/content/images/2017/07/docker-run-nodejs-hyperv.png-shadow.png" alt="docker run volume hyperv"></p>
<p>But this improvement in native Windows containers looks very promising to solve a lot of headache for all the maintainers of Git for Windows, Golang, Node.js and so on.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Having smaller Windows container images is a huge step forward. I encourage you to try out the much smaller images. You'll learn how it feels to work with them and you can give valuable feedback to the Microsoft Containers team shaping the next version of Windows Server.</p>
<p>Can we make even smaller images? I don't know, but let's find it out. How about naming the new images? Please make suggestions at the Microsoft Tech Community <a href="https://techcommunity.microsoft.com">https://techcommunity.microsoft.com</a>.</p>
<p>Please use the comments below if you have further ideas, questions or improvements to share. You can follow me on Twitter <a href="https://twitter.com/stefscherer">@stefscherer</a> to stay up to date with Windows containers.</p>
</div>]]></content:encoded></item><item><title><![CDATA[Use multi-stage builds for smaller Windows images]]></title><description><![CDATA[<div class="kg-card-markdown"><p>I'm still here in Austin, TX at DockerCon 2017 and I want to show you one of the announcements that is very useful to build small Windows Docker images.</p>
<p>On Tuesday's first keynote at DockerCon Solomon Hykes introduced the most impressive feature for me that will make it in version</p></div>]]></description><link>https://stefanscherer.github.io/use-multi-stage-builds-for-smaller-windows-images/</link><guid isPermaLink="false">5986d4ec688a490001540974</guid><category><![CDATA[Docker]]></category><category><![CDATA[windows-containers]]></category><category><![CDATA[multi-stage]]></category><dc:creator><![CDATA[Stefan Scherer]]></dc:creator><pubDate>Wed, 19 Apr 2017 22:52:00 GMT</pubDate><content:encoded><![CDATA[<div class="kg-card-markdown"><p>I'm still here in Austin, TX at DockerCon 2017 and I want to show you one of the announcements that is very useful to build small Windows Docker images.</p>
<p>On Tuesday's first keynote at DockerCon Solomon Hykes introduced the most impressive feature for me that will make it in version 17.05.0 of Docker: <strong>The multi-stage builds</strong></p>
<p><img src="https://stefanscherer.github.io/content/images/2017/04/multi-stage-build.jpg" alt="announcement at DockerCon about multi-stage builds"></p>
<p>The demo in the keynote only showed Linux images, but you can use this feature for Windows images as well.</p>
<h2 id="howdidwebuildsmallerimagesinthepast">How did we build smaller images in the past?</h2>
<p>As we know each instruction in a <code>Dockerfile</code> like <code>COPY</code> or <code>RUN</code> builds a new layer of the image. So everything you do in eg. a <code>RUN</code> instruction is atomic and saved into one layer. It was a common practise to use multi-line <code>RUN</code> instructions to clean up temporary files and cache folders before that instruction ends to minimize the size of that layer.</p>
<p>For me it always looked like a workaround and a little too technical to know where all these temporary files have to be wiped out. So it is great to remove this noise out of your Dockerfiles.</p>
<p>And another workaround that was used in addition was to create two Dockerfiles and a script to simulate such stages and copy files from the first Docker image back to the host and then into the second Docker image. This could lead to errors if you have old temp folders on your host where you copy the results from the first build in. So it will be good that we can remove this complexity and avoid such build scripts entirely.</p>
<h2 id="multistagebuildonwindows">Multi-stage build on Windows</h2>
<p>The idea behind multi-stage builds is that you can define two or more build stages and only the layers of the last stage gets into the final Docker image.</p>
<h3 id="thefirststage">The first stage</h3>
<p>As you can see in the nice slide you can start with a first stage and do what you like in there. Maybe you need a <strong>complete build environment</strong> like MSBuild, or the Golang compiler or dev dependencies to run Node.js tests with your sources.</p>
<p>The <code>FROM</code> instruction now can be followed by a stage name, eg. <code>build</code>. I recommend to introduce that to your <code>Dockefile</code> as we will need this name later again. This is how your Dockerfile then could look like:</p>
<pre><code class="language-Dockerfile">FROM microsoft/windowsservercore as build
</code></pre>
<p>You do not need to use multi-line <code>RUN</code> instructions any more if you haven't liked it. Just keep your Dockerfile <strong>simple, readable and maintainable</strong> by your team colleages. The advantage that even you have is that you can use the Docker build cache much better.</p>
<p>Think of a giant multi-line <code>RUN</code> instruction with three big downloads, uncompress and cleanup steps and the third download crashes due to internet connectivity. Then you have to do all the other downloads again if you start the <code>docker build</code> again.</p>
<p>So relax and just download one file per <code>RUN</code> instruction, even put the uncompress into another <code>RUN</code> layer, it doesn't matter for the final image size.</p>
<h3 id="thelaststage">The last stage</h3>
<p>The magic comes into the <code>Dockerfile</code> as you can use more than one <code>FROM</code> instructions. Each <code>FROM</code> starts a new build stage and all lines beginning from the last <code>FROM</code> will make it into the final Docker image. The last stage does not need to have a name like the previous ones.</p>
<p>In this last stage you define the <strong>minimal runtime environment</strong> for your containerised application.</p>
<p>The <code>COPY</code> instruction now has a new option <code>--from</code> where you can specify from with stage you want to copy files or directories into the current stage.</p>
<p>Enough theory. Let's have a look at some real use-cases I already tried out.</p>
<h2 id="buildagolangprogram">Build a Golang program</h2>
<p>A simple multi-stage <code>Dockerfile</code> to build a Golang binary from source could look like this:</p>
<pre><code class="language-Dockerfile">FROM golang:nanoserver as gobuild
COPY . /code
WORKDIR /code
RUN go build webserver.go

FROM microsoft/nanoserver
COPY --from=gobuild /code/webserver.exe /webserver.exe
EXPOSE 8080
CMD [&quot;\\webserver.exe&quot;]
</code></pre>
<p>The first four lines describe the normal build. We copy the source codes into the Golang build environment and build the Windows binary with it.</p>
<p>Then with the second <code>FROM</code> instruction we choose an empty NanoServer image. With this we skip about 100 MByte of compressed Golang build environment images for the production image.</p>
<p>The <code>COPY --from=gobuild</code> instruction copies the final Windows binary from the gobuild stage into the final stage.</p>
<p>The last two lines are just the normal things you do, expose the port on which your app is listening and describing the command that should be called when running a container with it.</p>
<p>This <code>Dockerfile</code> now can be easily be built as always with</p>
<pre><code>docker build -t webserver .
</code></pre>
<p>The final Docker image only has a 2 MByte compressed layer in addition to the NanoServer base layers.</p>
<p>You can find a full example for such a simple Golang webserver in my <a href="https://github.com/StefanScherer/dockerfiles-windows/tree/master/webserver">dockerfiles-windows</a> repo, the final Docker Hub image is available at <a href="https://hub.docker.com/r/stefanscherer/whoami/tags/"><code>stefanscherer/whoami:windows-amd64-1.2.0</code></a>.</p>
<h2 id="installmongodbmsiinnanoserver">Install MongoDB MSI in NanoServer</h2>
<p>Another example for this multi-stage build is that you can use it to <strong>install MSI packages</strong> and put the installed programs and files <strong>into a NanoServer</strong> image.</p>
<p>Well, you cannot install MSI packages in NanoServer directly, but you can <strong>start with the Windows Server Core</strong> image in the build stage and <strong>then switch to NanoServer</strong> in the final stage.</p>
<p>If you know where the software has been installed you can <code>COPY</code> deploy them in the final stage into the image.</p>
<p>The <code>Dockerfile</code> how to build a MongoDB NanoServer image is also available <a href="https://github.com/StefanScherer/dockerfiles-windows/blob/142debf6ddeb9f5fb57d2d472ebf166a32dbcc87/mongo/3.4/Dockerfile">on GitHub</a>.</p>
<p>The <a href="https://github.com/StefanScherer/dockerfiles-windows/blob/142debf6ddeb9f5fb57d2d472ebf166a32dbcc87/mongo/3.4/Dockerfile#L1-L18">first stage</a> more or less looks like this:</p>
<pre><code class="language-Dockerfile">FROM microsoft/windowsservercore as msi
RUN &quot;download MSI page&quot;
RUN &quot;check SHA sum of download&quot;
RUN &quot;run MSI installer&quot;
</code></pre>
<p>and the <a href="https://github.com/StefanScherer/dockerfiles-windows/blob/142debf6ddeb9f5fb57d2d472ebf166a32dbcc87/mongo/3.4/Dockerfile#L20-L32">final stage</a> looks like this:</p>
<pre><code class="language-Dockerfile">FROM microsoft/nanoserver
COPY --from=msi C:\mongodb\ C:\mongodb\
...
RUN &quot;put MongoDB binaries into PATH&quot;
VOLUME C:\data\db
EXPOSE 27017
CMD [&quot;mongod.exe&quot;]
</code></pre>
<p>Another pro tip: If you really want small Windows Docker images you should also avoid <code>RUN</code> or <code>ENV</code> instructions in the last stage.</p>
<p>The final MongoDB NanoServer image is available at <a href="https://hub.docker.com/r/stefanscherer/mongo-windows/tags/"><code>stefanscherer/mongo-windows:3.4.2-nano</code></a>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>With multi-stage builds coming into Docker 17.05 we will be able to</p>
<ul>
<li>put all build stages into a single Dockerfile to use only one simple <code>docker build</code> command</li>
<li>use the build cache by using single line <code>RUN</code> instructions</li>
<li>start with ServerCore, then switch to NanoServer</li>
<li>use latest NanoServer image with all security updates installed for the last stage even if upstream build layer may be out of date</li>
</ul>
<p>This gives you an idea what you will be able to do once you have Docker 17.05 or later installed.</p>
<p><strong>Update 2017-05-07</strong>: I build all my <a href="https://github.com/StefanScherer/dockerfiles-windows">dockerfiles-windows</a> Windows Docker images with <a href="https://www.appveyor.com">AppVeyor</a> and it is very easy to upgrade to Docker 17.05.0-ce during the build with the script <a href="https://github.com/StefanScherer/dockerfiles-windows/blob/d1c01effe957281f72a762914b7fae36bdf49c15/update-docker-ce.ps1"><code>update-docker-ce.ps1</code></a>. For local Windows Server 2016 VM's you could use this script as well. Sure, at the moment we have to switch from EE to CE edition until 17.06.0-ee also will bring this feature. Your images will still run on 17.03.1-ee production servers.</p>
<p>Please use the comments below if you have further ideas, questions or improvements to share. You can follow me on Twitter <a href="https://twitter.com/stefscherer">@stefscherer</a>.</p>
</div>]]></content:encoded></item><item><title><![CDATA[Yes, you can "Docker" on Windows 7]]></title><description><![CDATA[<div class="kg-card-markdown"><p>This week I was asked to help automating a task to get some Linux binaries and files packaged into a tarball. Some developers tried to spin up a Linux virtual machine and run a script to install tools and then do the packaging. Although I also like and use <a href="https://www.vagrantup.com">Vagrant</a></p></div>]]></description><link>https://stefanscherer.github.io/yes-you-can-docker-on-windows-7/</link><guid isPermaLink="false">5986d4ec688a490001540973</guid><category><![CDATA[Docker]]></category><category><![CDATA[Chocolatey]]></category><category><![CDATA[Windows 7]]></category><category><![CDATA[Docker Machine]]></category><category><![CDATA[VMware]]></category><dc:creator><![CDATA[Stefan Scherer]]></dc:creator><pubDate>Fri, 31 Mar 2017 17:02:07 GMT</pubDate><content:encoded><![CDATA[<div class="kg-card-markdown"><p>This week I was asked to help automating a task to get some Linux binaries and files packaged into a tarball. Some developers tried to spin up a Linux virtual machine and run a script to install tools and then do the packaging. Although I also like and use <a href="https://www.vagrantup.com">Vagrant</a> still very often, it seemed to me using <a href="https://www.docker.com">Docker</a> will be easier to maintain as this could be done in a one-shot container.</p>
<h2 id="thehardfactswindows7enterprise">The hard facts - Windows 7 Enterprise</h2>
<p>The bigger problem was the fact that in some companies you still find Windows 7 Enterprise. It may be a delayed rollout of new notebooks that keep the employees on that old desktop platform.</p>
<p>So using <a href="https://docs.docker.com/docker-for-windows/">Docker for Windows</a> was no option as it only works with Windows 10 Pro with Hyper-V. This looks like a good setup for new notebooks, but if you want to use Docker <em>now</em> you have to look for other solutions.</p>
<h2 id="lockedinhypervisor">Locked-in Hypervisor</h2>
<p>Next obstacle was that for Vagrant it is better to use <strong>VMware Workstation</strong> on Windows 7 instead of VirtualBox. There also may be a company policy to use one specific hypervisor as the knowledge is already there using other server products in the datacenter.</p>
<p>So going down to the <a href="https://www.docker.com/products/docker-toolbox">Docker Toolbox</a> also was no option as it comes with VirtualBox to run the Linux boot2docker VM.</p>
<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">Can&#39;t Believe this..GOT THIS GIF from my Kid :) <a href="https://twitter.com/docker">@docker</a> ..Amazing ! <a href="https://t.co/f09henl5Ta">pic.twitter.com/f09henl5Ta</a></p>&mdash; Ajeet Singh Raina (@ajeetsraina) <a href="https://twitter.com/ajeetsraina/status/847737267510591488">31. Mrz 2017</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<h2 id="embraceyourenvironment">Embrace your environment</h2>
<p>So we went with a manual installation of some Docker tools to get a Linux Docker VM running on the Windows 7 machine. Luckily the developers already had the <a href="https://chocolatey.org">Chocolatey</a> package manager installed.</p>
<p>Let's recap what I found on the notebooks</p>
<ul>
<li>Windows 7 Enterprise</li>
<li>VMware Workstation 9/10/11/12</li>
</ul>
<p>Well there is a tool Docker Machine to create local Docker VM's very easily, and there is a VMware Workstation plugin available. All these tools are also available as Chocolatey packages.</p>
<p>So what we did on the machines was installing three packages with these simple commands in an administrator terminal.</p>
<pre><code>choco install -y docker
choco install -y docker-machine
choco install -y docker-machine-vmwareworkstation
</code></pre>
<p>Then we closed the administrator terminal as the next commands can be done in normal user mode.</p>
<h2 id="myhostismycastle">My host is my castle</h2>
<p>Every developer installs tools that they need for their work. Installing that on the host machine - your desktop or notebook - leads to different machines.</p>
<p>Creating the Docker Machine we ran into a &quot;works on my machine, but doesn't work on your machine&quot; problem I hadn't seen before.</p>
<p>Something while setting up the Linux VM just went wrong. It turned out that copying the Docker TLS certs with SSH just didn't work. A deeper look on what else is installed on the host we found that some implementations of SSH clients just doesn't work very well.</p>
<p>Luckily there is a less known option in the <code>docker-machine</code> binary to ignore external SSH client and use the built-in implementation.</p>
<p>With that knowledge we were able to create a VMware Docker Machine on that laptop with</p>
<pre><code>docker-machine --native-ssh create -d vmwareworkstation default
</code></pre>
<p>Using the good old PowerShell on the Windows 7 notebook helps you to use that Linux Docker VM by setting some environment variables.</p>
<pre><code>docker-machine env | iex
</code></pre>
<p>After that you can run <code>docker version</code> for example to retrieve client and server version which are both the up-to-date community editions</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/03/docker-version.png" alt="docker version"></p>
<p>Quite exciting to be able to use that Windows 7 notebook with the latest Docker tools installed.</p>
<p>So hopefully Docker and using containers in more and more development tasks helps to keep their notebooks clean and they <strong>install less tools on the host</strong> and instead running more tools in containers.</p>
<h2 id="icancaproblem">I can C: a problem</h2>
<p>Using that Docker Machine VM worked really well until we faced another problem. Building some Docker images we ran out of disk space. Oh no, although the Windows 7 notebooks got improved by installing a 1 TB SSD, the C: partition hasn't been increased for some historical reasons.</p>
<p><img src="https://stefanscherer.github.io/content/images/2017/03/facepalm.jpg" alt="Face palm"></p>
<p>Docker Machine creates the Linux VM's in the current users home directory. This is a good idea, but having a 120 GB partition with only 7 GB left on C: we had to fix it. Taking a deep breath and embracing that environment, we came to the following solution.</p>
<p>We destroyed the Docker Machine again (because it's so easy) and also removed the <code>.docker</code> folder again to link it to a folder that resides on a bigger partition of the SSD.</p>
<pre><code>docker-machine rm -f default
rm $env:USERPROFILE\.docker
mkdir D:\docker
cmd /c mklink /J $env:USERPROFILE\.docker D:\docker
</code></pre>
<p>Then we recreated the Docker Machine with the command from above and set the environment variables again.</p>
<pre><code>docker-machine --native-ssh create -d vmwareworkstation default
docker-machine env | iex
</code></pre>
<p>And hurray - it worked. The VM with its disk resides on the bigger D: drive and we don't have to set any other global environment variables.</p>
<p>With that setup I made the developers happy. They could start using Docker without waiting for new hardware or asking their admins to resize or reformat their partitions.</p>
<p>We soon had a small <code>Dockerfile</code> and put the already existing provision scripts into an image. So we finished the task running a Linux container that can be thrown away more easily than a whole VM.</p>
<h2 id="dailywork">Daily work</h2>
<p>To recap how to use this Docker Machine you normally do the following steps after booting your notebook.</p>
<pre><code>docker-machine start
docker-machine env | iex
</code></pre>
<p>Then you can work with this default Linux Docker VM.</p>
<h2 id="planningyourhardwareupdate">Planning your hardware update</h2>
<p>The story ended well, but I recommended to think ahead and plan the next hardware update. So before they just get the new notebook generation they should think about which hypervisor they should use in the future.</p>
<p>Using Windows 10 Enterprise with the built-in Hyper-V would be easier. You can run <strong>native Windows containers</strong> with it and use <strong>Docker for Windows</strong> to switch between Linux and Windows containers. Using Vagrant with Hyper-V also gets better and better.</p>
<p>But if company policy still restricts you to use eg. VMware then you also can use the steps above to create a Linux Docker machine. You also cannot use Windows containers directly on Windows 10 machine as Hyper-V does not work in parallel with other hypervisors. In that case you might spin up a Windows Server 2016 VM using my <a href="https://github.com/StefanScherer/windows-docker-machine">Windows Docker Machine</a> setup. With that you can easily switch between Linux and Windows containers using the <code>docker-machine env</code> command.</p>
<p>As always, please leave a comment if you have questions or improvements or want to share your thoughts. I love to hear about your enterprise setup and how to make Docker work on your developer's machines. You can follow me on Twitter <a href="https://twitter.com/stefscherer">@stefscherer</a>.</p>
</div>]]></content:encoded></item></channel></rss>